{
  "version": "2",
  "toolVersion": "1.57.0",
  "snippets": {
    "cc40016d2d8004f99044f2e64d4481daefdf61e5e1c20a1cb4642e383b720c89": {
      "translations": {
        "python": {
          "source": "bucket = s3.Bucket(self, \"Bucket\")\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket)]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket = new Bucket(this, \"Bucket\");\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket) }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket = new Bucket(this, \"Bucket\");\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(new S3Bucket(bucket)))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "bucket := s3.NewBucket(this, jsii.String(\"Bucket\"))\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket),\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "const bucket = new s3.Bucket(this, 'Bucket');\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket)],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 40
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "aws-cdk-lib.aws_s3.Bucket",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\nconst bucket = new s3.Bucket(this, 'Bucket');\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket)],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 2,
        "75": 9,
        "104": 2,
        "192": 1,
        "193": 1,
        "194": 3,
        "197": 3,
        "225": 1,
        "226": 1,
        "242": 1,
        "243": 1,
        "281": 1
      },
      "fqnsFingerprint": "977b3a260b30316ec495f8d45265a1121d0ae03ae9d85258dbfc44a08a81601c"
    },
    "742e4416e4378c2838a11ef019ea3444729cd29a7a8cfbdc630ff8b70735ebb4": {
      "translations": {
        "python": {
          "source": "# destination: firehose.IDestination\n\nsource_stream = kinesis.Stream(self, \"Source Stream\")\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    source_stream=source_stream,\n    destinations=[destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "IDestination destination;\n\nStream sourceStream = new Stream(this, \"Source Stream\");\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    SourceStream = sourceStream,\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "IDestination destination;\n\nStream sourceStream = new Stream(this, \"Source Stream\");\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .sourceStream(sourceStream)\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var destination iDestination\nsourceStream := kinesis.NewStream(this, jsii.String(\"Source Stream\"))\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tsourceStream: sourceStream,\n\tdestinations: []*iDestination{\n\t\tdestination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "declare const destination: firehose.IDestination;\nconst sourceStream = new kinesis.Stream(this, 'Source Stream');\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  sourceStream: sourceStream,\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 68
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "aws-cdk-lib.aws_kinesis.IStream",
        "aws-cdk-lib.aws_kinesis.Stream"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const destination: firehose.IDestination;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst sourceStream = new kinesis.Stream(this, 'Source Stream');\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  sourceStream: sourceStream,\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 2,
        "75": 12,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 1,
        "194": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "a6ccec4775cb692985d2585c3ede15c47e827e5d6b02b73376fd9fef21cacaf8"
    },
    "01d0493539276c9d0c77a2042d0d999f8996fd6120d5fe6fa9395b8a08b617f2": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n\ns3_destination = destinations.S3Bucket(bucket)\n\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\n\nS3Bucket s3Destination = new S3Bucket(bucket);\n\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n\nS3Bucket s3Destination = new S3Bucket(bucket);\n\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket\ns3Destination := destinations.NewS3Bucket(bucket)\n\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\ts3Destination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "declare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket);\n\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 105
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst s3Destination = new destinations.S3Bucket(bucket);\n\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "75": 11,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 1,
        "194": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 1,
        "290": 1
      },
      "fqnsFingerprint": "8b5b60772deb60969018c977347b3f2269436fffd328f2efc62affb49f170da5"
    },
    "be65f12a911e1887d7ff5803f87dad4505abeb4bdfcb8c3d270cccabc64630fa": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n\ns3_destination = destinations.S3Bucket(bucket,\n    data_output_prefix=\"myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}\",\n    error_output_prefix=\"myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}\"\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\n\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    DataOutputPrefix = \"myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}\",\n    ErrorOutputPrefix = \"myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}\"\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .dataOutputPrefix(\"myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}\")\n        .errorOutputPrefix(\"myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}\")\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket\ns3Destination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tdataOutputPrefix: jsii.String(\"myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}\"),\n\terrorOutputPrefix: jsii.String(\"myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}\"),\n})",
          "version": "1"
        },
        "$": {
          "source": "declare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  dataOutputPrefix: 'myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}',\n  errorOutputPrefix: 'myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}',\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 118
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  dataOutputPrefix: 'myFirehose/DeliveredYear=!{timestamp:yyyy}/anyMonth/rand=!{firehose:random-string}',\n  errorOutputPrefix: 'myFirehoseFailures/!{firehose:error-output-type}/!{timestamp:yyyy}/anyMonth/!{timestamp:dd}',\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 2,
        "75": 9,
        "130": 1,
        "153": 1,
        "169": 1,
        "193": 1,
        "194": 1,
        "197": 1,
        "225": 2,
        "242": 2,
        "243": 2,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "03d7846a3579d00b3eed4c852a1033036eb6ddce86bad048df3f29289974a7c5"
    },
    "76169721d089fa7180b15dd99c2ad0985f7f78a3d477956033fd4313cfa3e197": {
      "translations": {
        "python": {
          "source": "# destination: firehose.IDestination\n# SSE with an customer-managed CMK that is explicitly specified\n# key: kms.Key\n\n\n# SSE with an AWS-owned CMK\nfirehose.DeliveryStream(self, \"Delivery Stream AWS Owned\",\n    encryption=firehose.StreamEncryption.AWS_OWNED,\n    destinations=[destination]\n)\n# SSE with an customer-managed CMK that is created automatically by the CDK\nfirehose.DeliveryStream(self, \"Delivery Stream Implicit Customer Managed\",\n    encryption=firehose.StreamEncryption.CUSTOMER_MANAGED,\n    destinations=[destination]\n)\nfirehose.DeliveryStream(self, \"Delivery Stream Explicit Customer Managed\",\n    encryption_key=key,\n    destinations=[destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "IDestination destination;\n// SSE with an customer-managed CMK that is explicitly specified\nKey key;\n\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nnew DeliveryStream(this, \"Delivery Stream AWS Owned\", new DeliveryStreamProps {\n    Encryption = StreamEncryption.AWS_OWNED,\n    Destinations = new [] { destination }\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew DeliveryStream(this, \"Delivery Stream Implicit Customer Managed\", new DeliveryStreamProps {\n    Encryption = StreamEncryption.CUSTOMER_MANAGED,\n    Destinations = new [] { destination }\n});\nnew DeliveryStream(this, \"Delivery Stream Explicit Customer Managed\", new DeliveryStreamProps {\n    EncryptionKey = key,\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "IDestination destination;\n// SSE with an customer-managed CMK that is explicitly specified\nKey key;\n\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nDeliveryStream.Builder.create(this, \"Delivery Stream AWS Owned\")\n        .encryption(StreamEncryption.AWS_OWNED)\n        .destinations(List.of(destination))\n        .build();\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nDeliveryStream.Builder.create(this, \"Delivery Stream Implicit Customer Managed\")\n        .encryption(StreamEncryption.CUSTOMER_MANAGED)\n        .destinations(List.of(destination))\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream Explicit Customer Managed\")\n        .encryptionKey(key)\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var destination iDestination\n// SSE with an customer-managed CMK that is explicitly specified\nvar key key\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream AWS Owned\"), &deliveryStreamProps{\n\tencryption: firehose.streamEncryption_AWS_OWNED,\n\tdestinations: []*iDestination{\n\t\tdestination,\n\t},\n})\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream Implicit Customer Managed\"), &deliveryStreamProps{\n\tencryption: firehose.*streamEncryption_CUSTOMER_MANAGED,\n\tdestinations: []*iDestination{\n\t\tdestination,\n\t},\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream Explicit Customer Managed\"), &deliveryStreamProps{\n\tencryptionKey: key,\n\tdestinations: []*iDestination{\n\t\tdestination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "declare const destination: firehose.IDestination;\n\n// SSE with an AWS-owned CMK\nnew firehose.DeliveryStream(this, 'Delivery Stream AWS Owned', {\n  encryption: firehose.StreamEncryption.AWS_OWNED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew firehose.DeliveryStream(this, 'Delivery Stream Implicit Customer Managed', {\n  encryption: firehose.StreamEncryption.CUSTOMER_MANAGED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is explicitly specified\ndeclare const key: kms.Key;\nnew firehose.DeliveryStream(this, 'Delivery Stream Explicit Customer Managed', {\n  encryptionKey: key,\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 148
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.StreamEncryption",
        "@aws-cdk/aws-kinesisfirehose-alpha.StreamEncryption#AWS_OWNED",
        "@aws-cdk/aws-kinesisfirehose-alpha.StreamEncryption#CUSTOMER_MANAGED",
        "aws-cdk-lib.aws_kms.IKey"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const destination: firehose.IDestination;\n// SSE with an customer-managed CMK that is explicitly specified\ndeclare const key: kms.Key;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\n\n// SSE with an AWS-owned CMK\nnew firehose.DeliveryStream(this, 'Delivery Stream AWS Owned', {\n  encryption: firehose.StreamEncryption.AWS_OWNED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew firehose.DeliveryStream(this, 'Delivery Stream Implicit Customer Managed', {\n  encryption: firehose.StreamEncryption.CUSTOMER_MANAGED,\n  destinations: [destination],\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream Explicit Customer Managed', {\n  encryptionKey: key,\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 3,
        "75": 28,
        "104": 3,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 3,
        "193": 3,
        "194": 7,
        "197": 3,
        "225": 2,
        "226": 3,
        "242": 2,
        "243": 2,
        "281": 6,
        "290": 1
      },
      "fqnsFingerprint": "dffc7ed2e88ba7a52da7841a27166fe5a43a7aa26af1c1479892338313b22505"
    },
    "fae66221312206df375e9a7138b9c9cb6299eaa92634aad2d6e15c37f0296d09": {
      "translations": {
        "python": {
          "source": "import aws_cdk.aws_logs as logs\n# bucket: s3.Bucket\n\n# destination: firehose.IDestination\n\n\nlog_group = logs.LogGroup(self, \"Log Group\")\ndestination = destinations.S3Bucket(bucket,\n    log_group=log_group\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "using Amazon.CDK.AWS.Logs;\nBucket bucket;\n\nIDestination destination;\n\n\nLogGroup logGroup = new LogGroup(this, \"Log Group\");\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps {\n    LogGroup = logGroup\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "import software.amazon.awscdk.services.logs.*;\nBucket bucket;\n\nIDestination destination;\n\n\nLogGroup logGroup = new LogGroup(this, \"Log Group\");\nS3Bucket destination = S3Bucket.Builder.create(bucket)\n        .logGroup(logGroup)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import logs \"github.com/aws/aws-cdk-go/awscdk\"\nvar bucket bucket\n\nvar destination iDestination\n\nlogGroup := logs.NewLogGroup(this, jsii.String(\"Log Group\"))\ndestination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tlogGroup: logGroup,\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []*iDestination{\n\t\tdestination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "import * as logs from 'aws-cdk-lib/aws-logs';\n\nconst logGroup = new logs.LogGroup(this, 'Log Group');\ndeclare const bucket: s3.Bucket;\nconst destination = new destinations.S3Bucket(bucket, {\n  logGroup: logGroup,\n});\n\ndeclare const destination: firehose.IDestination;\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 186
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_logs.LogGroup",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\nimport * as logs from 'aws-cdk-lib/aws-logs';\ndeclare const bucket: s3.Bucket;\n\ndeclare const destination: firehose.IDestination;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\n\nconst logGroup = new logs.LogGroup(this, 'Log Group');\nconst destination = new destinations.S3Bucket(bucket, {\n  logGroup: logGroup,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 3,
        "75": 20,
        "104": 2,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 1,
        "193": 2,
        "194": 3,
        "197": 3,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "254": 1,
        "255": 1,
        "256": 1,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "a8519714d6f48fcf8d10c948c8e558cee31223d0ea3a66a5aa32a3f53278a1db"
    },
    "27bdcf335467341a27b2c112aec94374e58f7db893f9c25a833a3f36a19ede58": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n\ndestination = destinations.S3Bucket(bucket,\n    logging=False\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\n\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps {\n    Logging = false\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n\nS3Bucket destination = S3Bucket.Builder.create(bucket)\n        .logging(false)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket\ndestination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tlogging: jsii.Boolean(false),\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "declare const bucket: s3.Bucket;\nconst destination = new destinations.S3Bucket(bucket, {\n  logging: false,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 203
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst destination = new destinations.S3Bucket(bucket, {\n  logging: false,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "75": 12,
        "91": 1,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 2,
        "194": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "b991bc7b45419b540e8c3d721e8a56cabe27220e16f8ffcadf89cc8eab688442"
    },
    "316bf41022243a9b39990c6be90124109594f799562749faf2aa36e119be1d32": {
      "translations": {
        "python": {
          "source": "import aws_cdk.aws_cloudwatch as cloudwatch\n# delivery_stream: firehose.DeliveryStream\n\n\n# Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nincoming_bytes_percent_of_limit = cloudwatch.MathExpression(\n    expression=\"incomingBytes / 300 / bytePerSecLimit\",\n    using_metrics={\n        \"incoming_bytes\": delivery_stream.metric_incoming_bytes(statistic=cloudwatch.Statistic.SUM),\n        \"byte_per_sec_limit\": delivery_stream.metric(\"BytesPerSecondLimit\")\n    }\n)\n\ncloudwatch.Alarm(self, \"Alarm\",\n    metric=incoming_bytes_percent_of_limit,\n    threshold=0.9,\n    evaluation_periods=3\n)",
          "version": "2"
        },
        "csharp": {
          "source": "using Amazon.CDK.AWS.CloudWatch;\nDeliveryStream deliveryStream;\n\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nMathExpression incomingBytesPercentOfLimit = new MathExpression(new MathExpressionProps {\n    Expression = \"incomingBytes / 300 / bytePerSecLimit\",\n    UsingMetrics = new Dictionary<string, IMetric> {\n        { \"incomingBytes\", deliveryStream.MetricIncomingBytes(new MetricOptions { Statistic = Statistic.SUM }) },\n        { \"bytePerSecLimit\", deliveryStream.Metric(\"BytesPerSecondLimit\") }\n    }\n});\n\nnew Alarm(this, \"Alarm\", new AlarmProps {\n    Metric = incomingBytesPercentOfLimit,\n    Threshold = 0.9,\n    EvaluationPeriods = 3\n});",
          "version": "1"
        },
        "java": {
          "source": "import software.amazon.awscdk.services.cloudwatch.*;\nDeliveryStream deliveryStream;\n\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nMathExpression incomingBytesPercentOfLimit = MathExpression.Builder.create()\n        .expression(\"incomingBytes / 300 / bytePerSecLimit\")\n        .usingMetrics(Map.of(\n                \"incomingBytes\", deliveryStream.metricIncomingBytes(MetricOptions.builder().statistic(Statistic.SUM).build()),\n                \"bytePerSecLimit\", deliveryStream.metric(\"BytesPerSecondLimit\")))\n        .build();\n\nAlarm.Builder.create(this, \"Alarm\")\n        .metric(incomingBytesPercentOfLimit)\n        .threshold(0.9)\n        .evaluationPeriods(3)\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import cloudwatch \"github.com/aws/aws-cdk-go/awscdk\"\nvar deliveryStream deliveryStream\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nincomingBytesPercentOfLimit := cloudwatch.NewMathExpression(&mathExpressionProps{\n\texpression: jsii.String(\"incomingBytes / 300 / bytePerSecLimit\"),\n\tusingMetrics: map[string]iMetric{\n\t\t\"incomingBytes\": deliveryStream.metricIncomingBytes(&MetricOptions{\n\t\t\t\"statistic\": cloudwatch.Statistic_SUM,\n\t\t}),\n\t\t\"bytePerSecLimit\": deliveryStream.metric(jsii.String(\"BytesPerSecondLimit\")),\n\t},\n})\n\ncloudwatch.NewAlarm(this, jsii.String(\"Alarm\"), &alarmProps{\n\tmetric: incomingBytesPercentOfLimit,\n\tthreshold: jsii.Number(0.9),\n\tevaluationPeriods: jsii.Number(3),\n})",
          "version": "1"
        },
        "$": {
          "source": "import * as cloudwatch from 'aws-cdk-lib/aws-cloudwatch';\ndeclare const deliveryStream: firehose.DeliveryStream;\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nconst incomingBytesPercentOfLimit = new cloudwatch.MathExpression({\n  expression: 'incomingBytes / 300 / bytePerSecLimit',\n  usingMetrics: {\n    incomingBytes: deliveryStream.metricIncomingBytes({ statistic: cloudwatch.Statistic.SUM }),\n    bytePerSecLimit: deliveryStream.metric('BytesPerSecondLimit'),\n  },\n});\n\nnew cloudwatch.Alarm(this, 'Alarm', {\n  metric: incomingBytesPercentOfLimit,\n  threshold: 0.9,\n  evaluationPeriods: 3,\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 233
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "aws-cdk-lib.aws_cloudwatch.Alarm",
        "aws-cdk-lib.aws_cloudwatch.AlarmProps",
        "aws-cdk-lib.aws_cloudwatch.IMetric",
        "aws-cdk-lib.aws_cloudwatch.MathExpression",
        "aws-cdk-lib.aws_cloudwatch.MathExpressionProps",
        "aws-cdk-lib.aws_cloudwatch.MetricOptions",
        "aws-cdk-lib.aws_cloudwatch.Statistic",
        "aws-cdk-lib.aws_cloudwatch.Statistic#SUM"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\nimport * as cloudwatch from 'aws-cdk-lib/aws-cloudwatch';\ndeclare const deliveryStream: firehose.DeliveryStream;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\n\n// Alarm that triggers when the per-second average of incoming bytes exceeds 90% of the current service limit\nconst incomingBytesPercentOfLimit = new cloudwatch.MathExpression({\n  expression: 'incomingBytes / 300 / bytePerSecLimit',\n  usingMetrics: {\n    incomingBytes: deliveryStream.metricIncomingBytes({ statistic: cloudwatch.Statistic.SUM }),\n    bytePerSecLimit: deliveryStream.metric('BytesPerSecondLimit'),\n  },\n});\n\nnew cloudwatch.Alarm(this, 'Alarm', {\n  metric: incomingBytesPercentOfLimit,\n  threshold: 0.9,\n  evaluationPeriods: 3,\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 2,
        "10": 4,
        "75": 25,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "193": 4,
        "194": 6,
        "196": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "254": 1,
        "255": 1,
        "256": 1,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "cf0f1977c4dc0582c075ed8854574e48e08d346ab403d059710167a6ce4b024b"
    },
    "f270cc6a2410d73314450181273d006cbfe796fc500b38b0c663661b556e1dae": {
      "translations": {
        "python": {
          "source": "# Compress data delivered to S3 using Snappy\n# bucket: s3.Bucket\n\ns3_destination = destinations.S3Bucket(bucket,\n    compression=destinations.Compression.SNAPPY\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// Compress data delivered to S3 using Snappy\nBucket bucket;\n\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Compression = Compression.SNAPPY\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "// Compress data delivered to S3 using Snappy\nBucket bucket;\n\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .compression(Compression.SNAPPY)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "// Compress data delivered to S3 using Snappy\nvar bucket bucket\ns3Destination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tcompression: destinations.compression_SNAPPY(),\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\ts3Destination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "// Compress data delivered to S3 using Snappy\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  compression: destinations.Compression.SNAPPY,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 264
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#SNAPPY",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// Compress data delivered to S3 using Snappy\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  compression: destinations.Compression.SNAPPY,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "75": 15,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 2,
        "194": 4,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "855cee35b7b4c822443d6f6769014165727666b7d0262cd812577a52d0285df5"
    },
    "77105e8e9a09b0b357ef46721c7238e0bdc6fdb359c78adb5b843c2cd9ca5a13": {
      "translations": {
        "python": {
          "source": "# Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\n# bucket: s3.Bucket\n\ndestination = destinations.S3Bucket(bucket,\n    buffering_interval=Duration.minutes(10),\n    buffering_size=Size.mebibytes(8)\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\nBucket bucket;\n\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps {\n    BufferingInterval = Duration.Minutes(10),\n    BufferingSize = Size.Mebibytes(8)\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\nBucket bucket;\n\nS3Bucket destination = S3Bucket.Builder.create(bucket)\n        .bufferingInterval(Duration.minutes(10))\n        .bufferingSize(Size.mebibytes(8))\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\nvar bucket bucket\ndestination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tbufferingInterval: duration.minutes(jsii.Number(10)),\n\tbufferingSize: size.mebibytes(jsii.Number(8)),\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\ndeclare const bucket: s3.Bucket;\nconst destination = new destinations.S3Bucket(bucket, {\n  bufferingInterval: Duration.minutes(10),\n  bufferingSize: Size.mebibytes(8),\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 284
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// Increase the buffer interval and size to 10 minutes and 8 MiB, respectively\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst destination = new destinations.S3Bucket(bucket, {\n  bufferingInterval: Duration.minutes(10),\n  bufferingSize: Size.mebibytes(8),\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 2,
        "10": 1,
        "75": 17,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 2,
        "194": 4,
        "196": 2,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 3,
        "290": 1
      },
      "fqnsFingerprint": "c29d92930e560a43884c7e28f01e38d040ea394c9a49a500582b9fa797d00e91"
    },
    "2bbd1f642fa05679d7ffd3b06973bb05c90d0c4b1bf1d8bb970d4031bea5c0ce": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n# key: kms.Key\n\ndestination = destinations.S3Bucket(bucket,\n    encryption_key=key\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\nKey key;\n\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps {\n    EncryptionKey = key\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\nKey key;\n\nS3Bucket destination = S3Bucket.Builder.create(bucket)\n        .encryptionKey(key)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket\nvar key key\ndestination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tencryptionKey: key,\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "declare const bucket: s3.Bucket;\ndeclare const key: kms.Key;\nconst destination = new destinations.S3Bucket(bucket, {\n  encryptionKey: key,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 308
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const bucket: s3.Bucket;\ndeclare const key: kms.Key;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nconst destination = new destinations.S3Bucket(bucket, {\n  encryptionKey: key,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "75": 16,
        "104": 1,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 1,
        "193": 2,
        "194": 2,
        "197": 2,
        "225": 3,
        "226": 1,
        "242": 3,
        "243": 3,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "186b6ac2866d119df1460115a64822a6b251fbc32a457c7c3be373cec0088bdb"
    },
    "36b10996b3d71423eebda8daf078bdf30dc01be20fd5ee63af2ba9b9a3dc552f": {
      "translations": {
        "python": {
          "source": "# Enable backup of all source records (to an S3 bucket created by CDK).\n# bucket: s3.Bucket\n# Explicitly provide an S3 bucket to which all source records will be backed up.\n# backup_bucket: s3.Bucket\n\nfirehose.DeliveryStream(self, \"Delivery Stream Backup All\",\n    destinations=[\n        destinations.S3Bucket(bucket,\n            s3_backup=destinations.DestinationS3BackupProps(\n                mode=destinations.BackupMode.ALL\n            )\n        )\n    ]\n)\nfirehose.DeliveryStream(self, \"Delivery Stream Backup All Explicit Bucket\",\n    destinations=[\n        destinations.S3Bucket(bucket,\n            s3_backup=destinations.DestinationS3BackupProps(\n                bucket=backup_bucket\n            )\n        )\n    ]\n)\n# Explicitly provide an S3 prefix under which all source records will be backed up.\nfirehose.DeliveryStream(self, \"Delivery Stream Backup All Explicit Prefix\",\n    destinations=[\n        destinations.S3Bucket(bucket,\n            s3_backup=destinations.DestinationS3BackupProps(\n                mode=destinations.BackupMode.ALL,\n                data_output_prefix=\"mybackup\"\n            )\n        )\n    ]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// Enable backup of all source records (to an S3 bucket created by CDK).\nBucket bucket;\n// Explicitly provide an S3 bucket to which all source records will be backed up.\nBucket backupBucket;\n\nnew DeliveryStream(this, \"Delivery Stream Backup All\", new DeliveryStreamProps {\n    Destinations = new [] {\n        new S3Bucket(bucket, new S3BucketProps {\n            S3Backup = new DestinationS3BackupProps {\n                Mode = BackupMode.ALL\n            }\n        }) }\n});\nnew DeliveryStream(this, \"Delivery Stream Backup All Explicit Bucket\", new DeliveryStreamProps {\n    Destinations = new [] {\n        new S3Bucket(bucket, new S3BucketProps {\n            S3Backup = new DestinationS3BackupProps {\n                Bucket = backupBucket\n            }\n        }) }\n});\n// Explicitly provide an S3 prefix under which all source records will be backed up.\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nnew DeliveryStream(this, \"Delivery Stream Backup All Explicit Prefix\", new DeliveryStreamProps {\n    Destinations = new [] {\n        new S3Bucket(bucket, new S3BucketProps {\n            S3Backup = new DestinationS3BackupProps {\n                Mode = BackupMode.ALL,\n                DataOutputPrefix = \"mybackup\"\n            }\n        }) }\n});",
          "version": "1"
        },
        "java": {
          "source": "// Enable backup of all source records (to an S3 bucket created by CDK).\nBucket bucket;\n// Explicitly provide an S3 bucket to which all source records will be backed up.\nBucket backupBucket;\n\nDeliveryStream.Builder.create(this, \"Delivery Stream Backup All\")\n        .destinations(List.of(\n            S3Bucket.Builder.create(bucket)\n                    .s3Backup(DestinationS3BackupProps.builder()\n                            .mode(BackupMode.ALL)\n                            .build())\n                    .build()))\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream Backup All Explicit Bucket\")\n        .destinations(List.of(\n            S3Bucket.Builder.create(bucket)\n                    .s3Backup(DestinationS3BackupProps.builder()\n                            .bucket(backupBucket)\n                            .build())\n                    .build()))\n        .build();\n// Explicitly provide an S3 prefix under which all source records will be backed up.\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nDeliveryStream.Builder.create(this, \"Delivery Stream Backup All Explicit Prefix\")\n        .destinations(List.of(\n            S3Bucket.Builder.create(bucket)\n                    .s3Backup(DestinationS3BackupProps.builder()\n                            .mode(BackupMode.ALL)\n                            .dataOutputPrefix(\"mybackup\")\n                            .build())\n                    .build()))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "// Enable backup of all source records (to an S3 bucket created by CDK).\nvar bucket bucket\n// Explicitly provide an S3 bucket to which all source records will be backed up.\nvar backupBucket bucket\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream Backup All\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.backupMode_ALL,\n\t\t\t},\n\t\t}),\n\t},\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream Backup All Explicit Bucket\"), &deliveryStreamProps{\n\tdestinations: []*iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tbucket: backupBucket,\n\t\t\t},\n\t\t}),\n\t},\n})\n// Explicitly provide an S3 prefix under which all source records will be backed up.\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream Backup All Explicit Prefix\"), &deliveryStreamProps{\n\tdestinations: []*iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.*backupMode_ALL,\n\t\t\t\tdataOutputPrefix: jsii.String(\"mybackup\"),\n\t\t\t},\n\t\t}),\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "// Enable backup of all source records (to an S3 bucket created by CDK).\ndeclare const bucket: s3.Bucket;\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        mode: destinations.BackupMode.ALL,\n      },\n    }),\n  ],\n});\n// Explicitly provide an S3 bucket to which all source records will be backed up.\ndeclare const backupBucket: s3.Bucket;\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All Explicit Bucket', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        bucket: backupBucket,\n      },\n    }),\n  ],\n});\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All Explicit Prefix', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        mode: destinations.BackupMode.ALL,\n        dataOutputPrefix: 'mybackup',\n      },\n    }),\n  ],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 329
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// Enable backup of all source records (to an S3 bucket created by CDK).\ndeclare const bucket: s3.Bucket;\n// Explicitly provide an S3 bucket to which all source records will be backed up.\ndeclare const backupBucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        mode: destinations.BackupMode.ALL,\n      },\n    }),\n  ],\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All Explicit Bucket', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        bucket: backupBucket,\n      },\n    }),\n  ],\n});\n// Explicitly provide an S3 prefix under which all source records will be backed up.\nnew firehose.DeliveryStream(this, 'Delivery Stream Backup All Explicit Prefix', {\n  destinations: [\n    new destinations.S3Bucket(bucket, {\n      s3Backup: {\n        mode: destinations.BackupMode.ALL,\n        dataOutputPrefix: 'mybackup',\n      },\n    }),\n  ],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 4,
        "75": 38,
        "104": 3,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 3,
        "193": 9,
        "194": 10,
        "197": 6,
        "225": 2,
        "226": 3,
        "242": 2,
        "243": 2,
        "281": 10,
        "290": 1
      },
      "fqnsFingerprint": "cb5447660629b23271b7e7da2285fc51e08b4d799ab42a1d6b157c0621df0968"
    },
    "a0e12351ba6e981d4179bd2e0062b5e1df51131dd5782b70c0f5d14048a69292": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n# Provide a Lambda function that will transform records before delivery, with custom\n# buffering and retry configuration\nlambda_function = lambda_.Function(self, \"Processor\",\n    runtime=lambda_.Runtime.NODEJS_12_X,\n    handler=\"index.handler\",\n    code=lambda_.Code.from_asset(path.join(__dirname, \"process-records\"))\n)\nlambda_processor = firehose.LambdaFunctionProcessor(lambda_function,\n    buffer_interval=Duration.minutes(5),\n    buffer_size=Size.mebibytes(5),\n    retries=5\n)\ns3_destination = destinations.S3Bucket(bucket,\n    processor=lambda_processor\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = new Function(this, \"Processor\", new FunctionProps {\n    Runtime = Runtime.NODEJS_12_X,\n    Handler = \"index.handler\",\n    Code = Code.FromAsset(Join(__dirname, \"process-records\"))\n});\nLambdaFunctionProcessor lambdaProcessor = new LambdaFunctionProcessor(lambdaFunction, new DataProcessorProps {\n    BufferInterval = Duration.Minutes(5),\n    BufferSize = Size.Mebibytes(5),\n    Retries = 5\n});\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Processor = lambdaProcessor\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = Function.Builder.create(this, \"Processor\")\n        .runtime(Runtime.NODEJS_12_X)\n        .handler(\"index.handler\")\n        .code(Code.fromAsset(join(__dirname, \"process-records\")))\n        .build();\nLambdaFunctionProcessor lambdaProcessor = LambdaFunctionProcessor.Builder.create(lambdaFunction)\n        .bufferInterval(Duration.minutes(5))\n        .bufferSize(Size.mebibytes(5))\n        .retries(5)\n        .build();\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .processor(lambdaProcessor)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nlambdaFunction := lambda.NewFunction(this, jsii.String(\"Processor\"), &functionProps{\n\truntime: lambda.runtime_NODEJS_12_X(),\n\thandler: jsii.String(\"index.handler\"),\n\tcode: lambda.code.fromAsset(path.join(__dirname, jsii.String(\"process-records\"))),\n})\nlambdaProcessor := firehose.NewLambdaFunctionProcessor(lambdaFunction, &dataProcessorProps{\n\tbufferInterval: duration.minutes(jsii.Number(5)),\n\tbufferSize: size.mebibytes(jsii.Number(5)),\n\tretries: jsii.Number(5),\n})\ns3Destination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tprocessor: lambdaProcessor,\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\ts3Destination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 395
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.aws_lambda.Code",
        "aws-cdk-lib.aws_lambda.Code#fromAsset",
        "aws-cdk-lib.aws_lambda.Function",
        "aws-cdk-lib.aws_lambda.FunctionProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda.Runtime",
        "aws-cdk-lib.aws_lambda.Runtime#NODEJS_12_X",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 3,
        "10": 4,
        "75": 39,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 11,
        "196": 4,
        "197": 4,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "19b84849c80cea41c51f2778c3be6760cd40dc358f5808896db488d18daa930a"
    },
    "06d04c5551e09d6ecb928e001defc0064e4f54d6110a97bc13c70005b60a3caa": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose_alpha as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "2"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "go": {
          "source": "import path \"github.com/aws-samples/dummy/path\"import firehose \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import kms \"github.com/aws/aws-cdk-go/awscdk\"import lambdanodejs \"github.com/aws/aws-cdk-go/awscdk\"import logs \"github.com/aws/aws-cdk-go/awscdk\"import s3 \"github.com/aws/aws-cdk-go/awscdk\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import destinations \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"\n\napp := cdk.NewApp()\n\nstack := cdk.NewStack(app, jsii.String(\"aws-cdk-firehose-delivery-stream-s3-all-properties\"))\n\nbucket := s3.NewBucket(stack, jsii.String(\"Bucket\"), &bucketProps{\n\tremovalPolicy: cdk.removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\n\nbackupBucket := s3.NewBucket(stack, jsii.String(\"BackupBucket\"), &bucketProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\nlogGroup := logs.NewLogGroup(stack, jsii.String(\"LogGroup\"), &logGroupProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\ndataProcessorFunction := lambdanodejs.NewNodejsFunction(stack, jsii.String(\"DataProcessorFunction\"), &nodejsFunctionProps{\n\tentry: path.join(__dirname, jsii.String(\"lambda-data-processor.js\")),\n\ttimeout: cdk.duration.minutes(jsii.Number(1)),\n})\n\nprocessor := firehose.NewLambdaFunctionProcessor(dataProcessorFunction, &dataProcessorProps{\n\tbufferInterval: cdk.*duration.seconds(jsii.Number(60)),\n\tbufferSize: cdk.size.mebibytes(jsii.Number(1)),\n\tretries: jsii.Number(1),\n})\n\nkey := kms.NewKey(stack, jsii.String(\"Key\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nbackupKey := kms.NewKey(stack, jsii.String(\"BackupKey\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nfirehose.NewDeliveryStream(stack, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\tlogging: jsii.Boolean(true),\n\t\t\tlogGroup: logGroup,\n\t\t\tprocessor: processor,\n\t\t\tcompression: destinations.compression_GZIP(),\n\t\t\tdataOutputPrefix: jsii.String(\"regularPrefix\"),\n\t\t\terrorOutputPrefix: jsii.String(\"errorPrefix\"),\n\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\tencryptionKey: key,\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.backupMode_ALL,\n\t\t\t\tbucket: backupBucket,\n\t\t\t\tcompression: destinations.*compression_ZIP(),\n\t\t\t\tdataOutputPrefix: jsii.String(\"backupPrefix\"),\n\t\t\t\terrorOutputPrefix: jsii.String(\"backupErrorPrefix\"),\n\t\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\t\tencryptionKey: backupKey,\n\t\t\t},\n\t\t}),\n\t},\n})\n\napp.synth()",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 417
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.App",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Duration#seconds",
        "aws-cdk-lib.RemovalPolicy",
        "aws-cdk-lib.RemovalPolicy#DESTROY",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.Stack",
        "aws-cdk-lib.Stage#synth",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_kms.Key",
        "aws-cdk-lib.aws_kms.KeyProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunctionProps",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_logs.LogGroup",
        "aws-cdk-lib.aws_logs.LogGroupProps",
        "aws-cdk-lib.aws_s3.Bucket",
        "aws-cdk-lib.aws_s3.BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as lambdanodejs from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cdk from 'aws-cdk-lib';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "47f33d4b0ee02f2364ebedbffe5a9fe2034492885858b06995f76713786ae1eb"
    },
    "2619061437063a4e7f689a7127f5d1b9bb12e98192b4bd9689de920fdee414db": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose_alpha as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "2"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "go": {
          "source": "import path \"github.com/aws-samples/dummy/path\"import firehose \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import kms \"github.com/aws/aws-cdk-go/awscdk\"import lambdanodejs \"github.com/aws/aws-cdk-go/awscdk\"import logs \"github.com/aws/aws-cdk-go/awscdk\"import s3 \"github.com/aws/aws-cdk-go/awscdk\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import destinations \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"\n\napp := cdk.NewApp()\n\nstack := cdk.NewStack(app, jsii.String(\"aws-cdk-firehose-delivery-stream-s3-all-properties\"))\n\nbucket := s3.NewBucket(stack, jsii.String(\"Bucket\"), &bucketProps{\n\tremovalPolicy: cdk.removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\n\nbackupBucket := s3.NewBucket(stack, jsii.String(\"BackupBucket\"), &bucketProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\nlogGroup := logs.NewLogGroup(stack, jsii.String(\"LogGroup\"), &logGroupProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\ndataProcessorFunction := lambdanodejs.NewNodejsFunction(stack, jsii.String(\"DataProcessorFunction\"), &nodejsFunctionProps{\n\tentry: path.join(__dirname, jsii.String(\"lambda-data-processor.js\")),\n\ttimeout: cdk.duration.minutes(jsii.Number(1)),\n})\n\nprocessor := firehose.NewLambdaFunctionProcessor(dataProcessorFunction, &dataProcessorProps{\n\tbufferInterval: cdk.*duration.seconds(jsii.Number(60)),\n\tbufferSize: cdk.size.mebibytes(jsii.Number(1)),\n\tretries: jsii.Number(1),\n})\n\nkey := kms.NewKey(stack, jsii.String(\"Key\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nbackupKey := kms.NewKey(stack, jsii.String(\"BackupKey\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nfirehose.NewDeliveryStream(stack, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\tlogging: jsii.Boolean(true),\n\t\t\tlogGroup: logGroup,\n\t\t\tprocessor: processor,\n\t\t\tcompression: destinations.compression_GZIP(),\n\t\t\tdataOutputPrefix: jsii.String(\"regularPrefix\"),\n\t\t\terrorOutputPrefix: jsii.String(\"errorPrefix\"),\n\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\tencryptionKey: key,\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.backupMode_ALL,\n\t\t\t\tbucket: backupBucket,\n\t\t\t\tcompression: destinations.*compression_ZIP(),\n\t\t\t\tdataOutputPrefix: jsii.String(\"backupPrefix\"),\n\t\t\t\terrorOutputPrefix: jsii.String(\"backupErrorPrefix\"),\n\t\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\t\tencryptionKey: backupKey,\n\t\t\t},\n\t\t}),\n\t},\n})\n\napp.synth()",
          "version": "1"
        },
        "$": {
          "source": "import * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as lambdanodejs from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cdk from 'aws-cdk-lib';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 421
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.App",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Duration#seconds",
        "aws-cdk-lib.RemovalPolicy",
        "aws-cdk-lib.RemovalPolicy#DESTROY",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.Stack",
        "aws-cdk-lib.Stage#synth",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_kms.Key",
        "aws-cdk-lib.aws_kms.KeyProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunctionProps",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_logs.LogGroup",
        "aws-cdk-lib.aws_logs.LogGroupProps",
        "aws-cdk-lib.aws_s3.Bucket",
        "aws-cdk-lib.aws_s3.BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as lambdanodejs from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cdk from 'aws-cdk-lib';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "47f33d4b0ee02f2364ebedbffe5a9fe2034492885858b06995f76713786ae1eb"
    },
    "d95b696fe32c17acb5afc443c3d9be91e78d2e66104da27aed291f8595440c09": {
      "translations": {
        "python": {
          "source": "# Specify the roles created above when defining the destination and delivery stream.\n# bucket: s3.Bucket\n# Create service roles for the delivery stream and destination.\n# These can be used for other purposes and granted access to different resources.\n# They must include the Kinesis Data Firehose service principal in their trust policies.\n# Two separate roles are shown below, but the same role can be used for both purposes.\ndelivery_stream_role = iam.Role(self, \"Delivery Stream Role\",\n    assumed_by=iam.ServicePrincipal(\"firehose.amazonaws.com\")\n)\ndestination_role = iam.Role(self, \"Destination Role\",\n    assumed_by=iam.ServicePrincipal(\"firehose.amazonaws.com\")\n)\ndestination = destinations.S3Bucket(bucket, role=destination_role)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[destination],\n    role=delivery_stream_role\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// Specify the roles created above when defining the destination and delivery stream.\nBucket bucket;\n// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\nRole deliveryStreamRole = new Role(this, \"Delivery Stream Role\", new RoleProps {\n    AssumedBy = new ServicePrincipal(\"firehose.amazonaws.com\")\n});\nRole destinationRole = new Role(this, \"Destination Role\", new RoleProps {\n    AssumedBy = new ServicePrincipal(\"firehose.amazonaws.com\")\n});\nS3Bucket destination = new S3Bucket(bucket, new S3BucketProps { Role = destinationRole });\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { destination },\n    Role = deliveryStreamRole\n});",
          "version": "1"
        },
        "java": {
          "source": "// Specify the roles created above when defining the destination and delivery stream.\nBucket bucket;\n// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\nRole deliveryStreamRole = Role.Builder.create(this, \"Delivery Stream Role\")\n        .assumedBy(new ServicePrincipal(\"firehose.amazonaws.com\"))\n        .build();\nRole destinationRole = Role.Builder.create(this, \"Destination Role\")\n        .assumedBy(new ServicePrincipal(\"firehose.amazonaws.com\"))\n        .build();\nS3Bucket destination = S3Bucket.Builder.create(bucket).role(destinationRole).build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(destination))\n        .role(deliveryStreamRole)\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "// Specify the roles created above when defining the destination and delivery stream.\nvar bucket bucket// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\ndeliveryStreamRole := iam.NewRole(this, jsii.String(\"Delivery Stream Role\"), &roleProps{\n\tassumedBy: iam.NewServicePrincipal(jsii.String(\"firehose.amazonaws.com\")),\n})\ndestinationRole := iam.NewRole(this, jsii.String(\"Destination Role\"), &roleProps{\n\tassumedBy: iam.NewServicePrincipal(jsii.String(\"firehose.amazonaws.com\")),\n})\ndestination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\trole: destinationRole,\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestination,\n\t},\n\trole: deliveryStreamRole,\n})",
          "version": "1"
        },
        "$": {
          "source": "// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\nconst deliveryStreamRole = new iam.Role(this, 'Delivery Stream Role', {\n  assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n});\nconst destinationRole = new iam.Role(this, 'Destination Role', {\n  assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n});\n\n// Specify the roles created above when defining the destination and delivery stream.\ndeclare const bucket: s3.Bucket;\nconst destination = new destinations.S3Bucket(bucket, { role: destinationRole });\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n  role: deliveryStreamRole,\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 513
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.aws_iam.IPrincipal",
        "aws-cdk-lib.aws_iam.IRole",
        "aws-cdk-lib.aws_iam.Role",
        "aws-cdk-lib.aws_iam.RoleProps",
        "aws-cdk-lib.aws_iam.ServicePrincipal",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\n\n// Specify the roles created above when defining the destination and delivery stream.\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Create service roles for the delivery stream and destination.\n// These can be used for other purposes and granted access to different resources.\n// They must include the Kinesis Data Firehose service principal in their trust policies.\n// Two separate roles are shown below, but the same role can be used for both purposes.\nconst deliveryStreamRole = new iam.Role(this, 'Delivery Stream Role', {\n  assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n});\nconst destinationRole = new iam.Role(this, 'Destination Role', {\n  assumedBy: new iam.ServicePrincipal('firehose.amazonaws.com'),\n});\nconst destination = new destinations.S3Bucket(bucket, { role: destinationRole });\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [destination],\n  role: deliveryStreamRole,\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 5,
        "75": 27,
        "104": 3,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 6,
        "197": 6,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 5,
        "290": 1
      },
      "fqnsFingerprint": "df0c3bc8e2f22656bd4529bd493863fe53f289d28e32cfa1acee407db926cc2f"
    },
    "cc935743f48fb7f0beb227d24592ee67bef6f049884e78a8d5eb277b5ac26ebe": {
      "translations": {
        "python": {
          "source": "# Give the role permissions to write data to the delivery stream\n# delivery_stream: firehose.DeliveryStream\nlambda_role = iam.Role(self, \"Role\",\n    assumed_by=iam.ServicePrincipal(\"lambda.amazonaws.com\")\n)\ndelivery_stream.grant_put_records(lambda_role)",
          "version": "2"
        },
        "csharp": {
          "source": "// Give the role permissions to write data to the delivery stream\nDeliveryStream deliveryStream;\nRole lambdaRole = new Role(this, \"Role\", new RoleProps {\n    AssumedBy = new ServicePrincipal(\"lambda.amazonaws.com\")\n});\ndeliveryStream.GrantPutRecords(lambdaRole);",
          "version": "1"
        },
        "java": {
          "source": "// Give the role permissions to write data to the delivery stream\nDeliveryStream deliveryStream;\nRole lambdaRole = Role.Builder.create(this, \"Role\")\n        .assumedBy(new ServicePrincipal(\"lambda.amazonaws.com\"))\n        .build();\ndeliveryStream.grantPutRecords(lambdaRole);",
          "version": "1"
        },
        "go": {
          "source": "// Give the role permissions to write data to the delivery stream\nvar deliveryStream deliveryStreamlambdaRole := iam.NewRole(this, jsii.String(\"Role\"), &roleProps{\n\tassumedBy: iam.NewServicePrincipal(jsii.String(\"lambda.amazonaws.com\")),\n})\ndeliveryStream.grantPutRecords(lambdaRole)",
          "version": "1"
        },
        "$": {
          "source": "const lambdaRole = new iam.Role(this, 'Role', {\n  assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n});\n\n// Give the role permissions to write data to the delivery stream\ndeclare const deliveryStream: firehose.DeliveryStream;\ndeliveryStream.grantPutRecords(lambdaRole);",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 550
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "aws-cdk-lib.aws_iam.IGrantable",
        "aws-cdk-lib.aws_iam.IPrincipal",
        "aws-cdk-lib.aws_iam.Role",
        "aws-cdk-lib.aws_iam.RoleProps",
        "aws-cdk-lib.aws_iam.ServicePrincipal"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\n\n// Give the role permissions to write data to the delivery stream\ndeclare const deliveryStream: firehose.DeliveryStream;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\nconst lambdaRole = new iam.Role(this, 'Role', {\n  assumedBy: new iam.ServicePrincipal('lambda.amazonaws.com'),\n});\ndeliveryStream.grantPutRecords(lambdaRole);\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 2,
        "75": 12,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "193": 1,
        "194": 3,
        "196": 1,
        "197": 2,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 1,
        "290": 1
      },
      "fqnsFingerprint": "ed9b8fe5150c0498a4092ae9261b4f9ef799738debdc08a2aa29af7e7ffa88dd"
    },
    "b6adad30168d44c99f55e478ed5bf74e7fd9f38d72b7a22531c49228c40484fc": {
      "translations": {
        "python": {
          "source": "# delivery_stream: firehose.DeliveryStream\nfn = lambda_.Function(self, \"Function\",\n    code=lambda_.Code.from_inline(\"exports.handler = (event) => {}\"),\n    runtime=lambda_.Runtime.NODEJS_14_X,\n    handler=\"index.handler\"\n)\nfn.grant_invoke(delivery_stream)",
          "version": "2"
        },
        "csharp": {
          "source": "DeliveryStream deliveryStream;\nFunction fn = new Function(this, \"Function\", new FunctionProps {\n    Code = Code.FromInline(\"exports.handler = (event) => {}\"),\n    Runtime = Runtime.NODEJS_14_X,\n    Handler = \"index.handler\"\n});\nfn.GrantInvoke(deliveryStream);",
          "version": "1"
        },
        "java": {
          "source": "DeliveryStream deliveryStream;\nFunction fn = Function.Builder.create(this, \"Function\")\n        .code(Code.fromInline(\"exports.handler = (event) => {}\"))\n        .runtime(Runtime.NODEJS_14_X)\n        .handler(\"index.handler\")\n        .build();\nfn.grantInvoke(deliveryStream);",
          "version": "1"
        },
        "go": {
          "source": "var deliveryStream deliveryStreamfn := lambda.NewFunction(this, jsii.String(\"Function\"), &functionProps{\n\tcode: lambda.code.fromInline(jsii.String(\"exports.handler = (event) => {}\")),\n\truntime: lambda.runtime_NODEJS_14_X(),\n\thandler: jsii.String(\"index.handler\"),\n})\nfn.grantInvoke(deliveryStream)",
          "version": "1"
        },
        "$": {
          "source": "const fn = new lambda.Function(this, 'Function', {\n  code: lambda.Code.fromInline('exports.handler = (event) => {}'),\n  runtime: lambda.Runtime.NODEJS_14_X,\n  handler: 'index.handler',\n});\n\ndeclare const deliveryStream: firehose.DeliveryStream;\nfn.grantInvoke(deliveryStream);",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 575
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "aws-cdk-lib.aws_iam.IGrantable",
        "aws-cdk-lib.aws_lambda.Code",
        "aws-cdk-lib.aws_lambda.Code#fromInline",
        "aws-cdk-lib.aws_lambda.Function",
        "aws-cdk-lib.aws_lambda.FunctionBase#grantInvoke",
        "aws-cdk-lib.aws_lambda.FunctionProps",
        "aws-cdk-lib.aws_lambda.Runtime",
        "aws-cdk-lib.aws_lambda.Runtime#NODEJS_14_X"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\n\ndeclare const deliveryStream: firehose.DeliveryStream;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\nconst fn = new lambda.Function(this, 'Function', {\n  code: lambda.Code.fromInline('exports.handler = (event) => {}'),\n  runtime: lambda.Runtime.NODEJS_14_X,\n  handler: 'index.handler',\n});\nfn.grantInvoke(deliveryStream);\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 3,
        "75": 18,
        "104": 1,
        "130": 1,
        "153": 1,
        "169": 1,
        "193": 1,
        "194": 6,
        "196": 2,
        "197": 1,
        "225": 2,
        "226": 1,
        "242": 2,
        "243": 2,
        "281": 3,
        "290": 1
      },
      "fqnsFingerprint": "2fbbcbebc1272c94bfdc1d8fe1b4346af06193d1e762caa328f7e2df6bb4e2ab"
    },
    "4a0ae51ec39f3536094e50eede775188f64e4422c25f1c3b445313e22f349560": {
      "translations": {
        "python": {
          "source": "# The code below shows an example of how to instantiate this type.\n# The values are placeholders you should change.\nimport aws_cdk.aws_kinesisfirehose_alpha as kinesisfirehose_alpha\nfrom aws_cdk import aws_iam as iam\n\n# role: iam.Role\n\ndata_processor_bind_options = kinesisfirehose_alpha.DataProcessorBindOptions(\n    role=role\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.IAM;\n\nRole role;\n\nDataProcessorBindOptions dataProcessorBindOptions = new DataProcessorBindOptions {\n    Role = role\n};",
          "version": "1"
        },
        "java": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.iam.*;\n\nRole role;\n\nDataProcessorBindOptions dataProcessorBindOptions = DataProcessorBindOptions.builder()\n        .role(role)\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import kinesisfirehose_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import awscdk \"github.com/aws/aws-cdk-go/awscdk\"import iam \"github.com/aws/aws-cdk-go/awscdk/aws_iam\"\n\nvar role role\ndataProcessorBindOptions := &dataProcessorBindOptions{\n\trole: role,\n}",
          "version": "1"
        },
        "$": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport { aws_iam as iam } from 'aws-cdk-lib';\n\ndeclare const role: iam.Role;\nconst dataProcessorBindOptions: kinesisfirehose_alpha.DataProcessorBindOptions = {\n  role: role,\n};",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorBindOptions"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorBindOptions",
        "aws-cdk-lib.aws_iam.IRole"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport { aws_iam as iam } from 'aws-cdk-lib';\n\ndeclare const role: iam.Role;\n/// !hide\n// Hoisted imports ended before !hide marker above\nimport { Construct } from \"constructs\";\nclass MyConstruct extends Construct {\nconstructor(scope: Construct, id: string) {\nsuper(scope, id);\n// Code snippet begins after !show marker below\n/// !show\n\nconst dataProcessorBindOptions: kinesisfirehose_alpha.DataProcessorBindOptions = {\n  role: role,\n};\n/// !hide\n// Code snippet ended before !hide marker above\n} }",
      "syntaxKindCounter": {
        "10": 2,
        "75": 11,
        "130": 1,
        "153": 2,
        "169": 2,
        "193": 1,
        "225": 2,
        "242": 2,
        "243": 2,
        "254": 2,
        "255": 2,
        "256": 1,
        "257": 1,
        "258": 1,
        "281": 1,
        "290": 1
      },
      "fqnsFingerprint": "b4628cce43d6d9aca7423e98ce9102528585fa70a7e88c5dcc3ce01c68dffdd0"
    },
    "33cb78a4a9a1d9349fefcad888d6002824f2c555ce681fd7f1ab6f2c1fd8fd33": {
      "translations": {
        "python": {
          "source": "# The code below shows an example of how to instantiate this type.\n# The values are placeholders you should change.\nimport aws_cdk.aws_kinesisfirehose_alpha as kinesisfirehose_alpha\n\ndata_processor_config = kinesisfirehose_alpha.DataProcessorConfig(\n    processor_identifier=kinesisfirehose_alpha.DataProcessorIdentifier(\n        parameter_name=\"parameterName\",\n        parameter_value=\"parameterValue\"\n    ),\n    processor_type=\"processorType\"\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\n\nDataProcessorConfig dataProcessorConfig = new DataProcessorConfig {\n    ProcessorIdentifier = new DataProcessorIdentifier {\n        ParameterName = \"parameterName\",\n        ParameterValue = \"parameterValue\"\n    },\n    ProcessorType = \"processorType\"\n};",
          "version": "1"
        },
        "java": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\n\nDataProcessorConfig dataProcessorConfig = DataProcessorConfig.builder()\n        .processorIdentifier(DataProcessorIdentifier.builder()\n                .parameterName(\"parameterName\")\n                .parameterValue(\"parameterValue\")\n                .build())\n        .processorType(\"processorType\")\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import kinesisfirehose_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"\ndataProcessorConfig := &dataProcessorConfig{\n\tprocessorIdentifier: &dataProcessorIdentifier{\n\t\tparameterName: jsii.String(\"parameterName\"),\n\t\tparameterValue: jsii.String(\"parameterValue\"),\n\t},\n\tprocessorType: jsii.String(\"processorType\"),\n}",
          "version": "1"
        },
        "$": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nconst dataProcessorConfig: kinesisfirehose_alpha.DataProcessorConfig = {\n  processorIdentifier: {\n    parameterName: 'parameterName',\n    parameterValue: 'parameterValue',\n  },\n  processorType: 'processorType',\n};",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorConfig"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorConfig",
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorIdentifier"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\n/// !hide\n// Hoisted imports ended before !hide marker above\nimport { Construct } from \"constructs\";\nclass MyConstruct extends Construct {\nconstructor(scope: Construct, id: string) {\nsuper(scope, id);\n// Code snippet begins after !show marker below\n/// !show\n\nconst dataProcessorConfig: kinesisfirehose_alpha.DataProcessorConfig = {\n  processorIdentifier: {\n    parameterName: 'parameterName',\n    parameterValue: 'parameterValue',\n  },\n  processorType: 'processorType',\n};\n/// !hide\n// Code snippet ended before !hide marker above\n} }",
      "syntaxKindCounter": {
        "10": 4,
        "75": 8,
        "153": 1,
        "169": 1,
        "193": 2,
        "225": 1,
        "242": 1,
        "243": 1,
        "254": 1,
        "255": 1,
        "256": 1,
        "281": 4,
        "290": 1
      },
      "fqnsFingerprint": "023a9cf48d179311a67b4b01fddf8c68e58e2af89d163ff5e1c7b541b07c6366"
    },
    "bbb0ad5d35fd0b76a6ffbd6334bb3ed64c456222a9556bc6423297f96f6acadd": {
      "translations": {
        "python": {
          "source": "\"Lambda\"",
          "version": "2"
        },
        "csharp": {
          "source": "\"Lambda\";",
          "version": "1"
        },
        "java": {
          "source": "\"Lambda\";",
          "version": "1"
        },
        "go": {
          "source": "\"Lambda\"",
          "version": "1"
        },
        "$": {
          "source": "'Lambda'",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "member",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorConfig",
          "memberName": "processorType"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [],
      "fullSource": "// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n'Lambda'\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 1,
        "226": 1
      },
      "fqnsFingerprint": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
    },
    "ee3c2e0cd9a608ee24bdab4303cc58293d5740c27ccfbdb0832c68b906054f07": {
      "translations": {
        "python": {
          "source": "# The code below shows an example of how to instantiate this type.\n# The values are placeholders you should change.\nimport aws_cdk.aws_kinesisfirehose_alpha as kinesisfirehose_alpha\n\ndata_processor_identifier = kinesisfirehose_alpha.DataProcessorIdentifier(\n    parameter_name=\"parameterName\",\n    parameter_value=\"parameterValue\"\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\n\nDataProcessorIdentifier dataProcessorIdentifier = new DataProcessorIdentifier {\n    ParameterName = \"parameterName\",\n    ParameterValue = \"parameterValue\"\n};",
          "version": "1"
        },
        "java": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\n\nDataProcessorIdentifier dataProcessorIdentifier = DataProcessorIdentifier.builder()\n        .parameterName(\"parameterName\")\n        .parameterValue(\"parameterValue\")\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import kinesisfirehose_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"\ndataProcessorIdentifier := &dataProcessorIdentifier{\n\tparameterName: jsii.String(\"parameterName\"),\n\tparameterValue: jsii.String(\"parameterValue\"),\n}",
          "version": "1"
        },
        "$": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nconst dataProcessorIdentifier: kinesisfirehose_alpha.DataProcessorIdentifier = {\n  parameterName: 'parameterName',\n  parameterValue: 'parameterValue',\n};",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorIdentifier"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorIdentifier"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\n/// !hide\n// Hoisted imports ended before !hide marker above\nimport { Construct } from \"constructs\";\nclass MyConstruct extends Construct {\nconstructor(scope: Construct, id: string) {\nsuper(scope, id);\n// Code snippet begins after !show marker below\n/// !show\n\nconst dataProcessorIdentifier: kinesisfirehose_alpha.DataProcessorIdentifier = {\n  parameterName: 'parameterName',\n  parameterValue: 'parameterValue',\n};\n/// !hide\n// Code snippet ended before !hide marker above\n} }",
      "syntaxKindCounter": {
        "10": 3,
        "75": 6,
        "153": 1,
        "169": 1,
        "193": 1,
        "225": 1,
        "242": 1,
        "243": 1,
        "254": 1,
        "255": 1,
        "256": 1,
        "281": 2,
        "290": 1
      },
      "fqnsFingerprint": "6a0c3e0104bf91d030a04ba383ff802989a3c6c0c8253a43d2e8cb151add4120"
    },
    "3655d6bd9a228ed395e5374782464b0c7aeee105c098133a7ac204f16b2be42f": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose_alpha as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "2"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "go": {
          "source": "import path \"github.com/aws-samples/dummy/path\"import firehose \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import kms \"github.com/aws/aws-cdk-go/awscdk\"import lambdanodejs \"github.com/aws/aws-cdk-go/awscdk\"import logs \"github.com/aws/aws-cdk-go/awscdk\"import s3 \"github.com/aws/aws-cdk-go/awscdk\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import destinations \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"\n\napp := cdk.NewApp()\n\nstack := cdk.NewStack(app, jsii.String(\"aws-cdk-firehose-delivery-stream-s3-all-properties\"))\n\nbucket := s3.NewBucket(stack, jsii.String(\"Bucket\"), &bucketProps{\n\tremovalPolicy: cdk.removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\n\nbackupBucket := s3.NewBucket(stack, jsii.String(\"BackupBucket\"), &bucketProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\nlogGroup := logs.NewLogGroup(stack, jsii.String(\"LogGroup\"), &logGroupProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\ndataProcessorFunction := lambdanodejs.NewNodejsFunction(stack, jsii.String(\"DataProcessorFunction\"), &nodejsFunctionProps{\n\tentry: path.join(__dirname, jsii.String(\"lambda-data-processor.js\")),\n\ttimeout: cdk.duration.minutes(jsii.Number(1)),\n})\n\nprocessor := firehose.NewLambdaFunctionProcessor(dataProcessorFunction, &dataProcessorProps{\n\tbufferInterval: cdk.*duration.seconds(jsii.Number(60)),\n\tbufferSize: cdk.size.mebibytes(jsii.Number(1)),\n\tretries: jsii.Number(1),\n})\n\nkey := kms.NewKey(stack, jsii.String(\"Key\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nbackupKey := kms.NewKey(stack, jsii.String(\"BackupKey\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nfirehose.NewDeliveryStream(stack, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\tlogging: jsii.Boolean(true),\n\t\t\tlogGroup: logGroup,\n\t\t\tprocessor: processor,\n\t\t\tcompression: destinations.compression_GZIP(),\n\t\t\tdataOutputPrefix: jsii.String(\"regularPrefix\"),\n\t\t\terrorOutputPrefix: jsii.String(\"errorPrefix\"),\n\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\tencryptionKey: key,\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.backupMode_ALL,\n\t\t\t\tbucket: backupBucket,\n\t\t\t\tcompression: destinations.*compression_ZIP(),\n\t\t\t\tdataOutputPrefix: jsii.String(\"backupPrefix\"),\n\t\t\t\terrorOutputPrefix: jsii.String(\"backupErrorPrefix\"),\n\t\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\t\tencryptionKey: backupKey,\n\t\t\t},\n\t\t}),\n\t},\n})\n\napp.synth()",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.App",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Duration#seconds",
        "aws-cdk-lib.RemovalPolicy",
        "aws-cdk-lib.RemovalPolicy#DESTROY",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.Stack",
        "aws-cdk-lib.Stage#synth",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_kms.Key",
        "aws-cdk-lib.aws_kms.KeyProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunctionProps",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_logs.LogGroup",
        "aws-cdk-lib.aws_logs.LogGroupProps",
        "aws-cdk-lib.aws_s3.Bucket",
        "aws-cdk-lib.aws_s3.BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as lambdanodejs from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cdk from 'aws-cdk-lib';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "47f33d4b0ee02f2364ebedbffe5a9fe2034492885858b06995f76713786ae1eb"
    },
    "44ae8c6a53a81ce60315d1041d7a2955185eecfb6e2d8e18af2e6c15eba938cc": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n# Provide a Lambda function that will transform records before delivery, with custom\n# buffering and retry configuration\nlambda_function = lambda_.Function(self, \"Processor\",\n    runtime=lambda_.Runtime.NODEJS_12_X,\n    handler=\"index.handler\",\n    code=lambda_.Code.from_asset(path.join(__dirname, \"process-records\"))\n)\nlambda_processor = firehose.LambdaFunctionProcessor(lambda_function,\n    buffer_interval=Duration.minutes(5),\n    buffer_size=Size.mebibytes(5),\n    retries=5\n)\ns3_destination = destinations.S3Bucket(bucket,\n    processor=lambda_processor\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = new Function(this, \"Processor\", new FunctionProps {\n    Runtime = Runtime.NODEJS_12_X,\n    Handler = \"index.handler\",\n    Code = Code.FromAsset(Join(__dirname, \"process-records\"))\n});\nLambdaFunctionProcessor lambdaProcessor = new LambdaFunctionProcessor(lambdaFunction, new DataProcessorProps {\n    BufferInterval = Duration.Minutes(5),\n    BufferSize = Size.Mebibytes(5),\n    Retries = 5\n});\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Processor = lambdaProcessor\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = Function.Builder.create(this, \"Processor\")\n        .runtime(Runtime.NODEJS_12_X)\n        .handler(\"index.handler\")\n        .code(Code.fromAsset(join(__dirname, \"process-records\")))\n        .build();\nLambdaFunctionProcessor lambdaProcessor = LambdaFunctionProcessor.Builder.create(lambdaFunction)\n        .bufferInterval(Duration.minutes(5))\n        .bufferSize(Size.mebibytes(5))\n        .retries(5)\n        .build();\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .processor(lambdaProcessor)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nlambdaFunction := lambda.NewFunction(this, jsii.String(\"Processor\"), &functionProps{\n\truntime: lambda.runtime_NODEJS_12_X(),\n\thandler: jsii.String(\"index.handler\"),\n\tcode: lambda.code.fromAsset(path.join(__dirname, jsii.String(\"process-records\"))),\n})\nlambdaProcessor := firehose.NewLambdaFunctionProcessor(lambdaFunction, &dataProcessorProps{\n\tbufferInterval: duration.minutes(jsii.Number(5)),\n\tbufferSize: size.mebibytes(jsii.Number(5)),\n\tretries: jsii.Number(5),\n})\ns3Destination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tprocessor: lambdaProcessor,\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\ts3Destination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.aws_lambda.Code",
        "aws-cdk-lib.aws_lambda.Code#fromAsset",
        "aws-cdk-lib.aws_lambda.Function",
        "aws-cdk-lib.aws_lambda.FunctionProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda.Runtime",
        "aws-cdk-lib.aws_lambda.Runtime#NODEJS_12_X",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 3,
        "10": 4,
        "75": 39,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 11,
        "196": 4,
        "197": 4,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "19b84849c80cea41c51f2778c3be6760cd40dc358f5808896db488d18daa930a"
    },
    "8a5946d1a500580aa54d9e7aa2b5627137a77978e48e411634dac6c8677b2b98": {
      "translations": {
        "python": {
          "source": "# The code below shows an example of how to instantiate this type.\n# The values are placeholders you should change.\nimport aws_cdk.aws_kinesisfirehose_alpha as kinesisfirehose_alpha\nfrom aws_cdk import aws_iam as iam\n\n# role: iam.Role\n\ndelivery_stream_attributes = kinesisfirehose_alpha.DeliveryStreamAttributes(\n    delivery_stream_arn=\"deliveryStreamArn\",\n    delivery_stream_name=\"deliveryStreamName\",\n    role=role\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.IAM;\n\nRole role;\n\nDeliveryStreamAttributes deliveryStreamAttributes = new DeliveryStreamAttributes {\n    DeliveryStreamArn = \"deliveryStreamArn\",\n    DeliveryStreamName = \"deliveryStreamName\",\n    Role = role\n};",
          "version": "1"
        },
        "java": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.iam.*;\n\nRole role;\n\nDeliveryStreamAttributes deliveryStreamAttributes = DeliveryStreamAttributes.builder()\n        .deliveryStreamArn(\"deliveryStreamArn\")\n        .deliveryStreamName(\"deliveryStreamName\")\n        .role(role)\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import kinesisfirehose_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import awscdk \"github.com/aws/aws-cdk-go/awscdk\"import iam \"github.com/aws/aws-cdk-go/awscdk/aws_iam\"\n\nvar role role\ndeliveryStreamAttributes := &deliveryStreamAttributes{\n\tdeliveryStreamArn: jsii.String(\"deliveryStreamArn\"),\n\tdeliveryStreamName: jsii.String(\"deliveryStreamName\"),\n\trole: role,\n}",
          "version": "1"
        },
        "$": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport { aws_iam as iam } from 'aws-cdk-lib';\n\ndeclare const role: iam.Role;\nconst deliveryStreamAttributes: kinesisfirehose_alpha.DeliveryStreamAttributes = {\n  deliveryStreamArn: 'deliveryStreamArn',\n  deliveryStreamName: 'deliveryStreamName',\n  role: role,\n};",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamAttributes"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamAttributes",
        "aws-cdk-lib.aws_iam.IRole"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport { aws_iam as iam } from 'aws-cdk-lib';\n\ndeclare const role: iam.Role;\n/// !hide\n// Hoisted imports ended before !hide marker above\nimport { Construct } from \"constructs\";\nclass MyConstruct extends Construct {\nconstructor(scope: Construct, id: string) {\nsuper(scope, id);\n// Code snippet begins after !show marker below\n/// !show\n\nconst deliveryStreamAttributes: kinesisfirehose_alpha.DeliveryStreamAttributes = {\n  deliveryStreamArn: 'deliveryStreamArn',\n  deliveryStreamName: 'deliveryStreamName',\n  role: role,\n};\n/// !hide\n// Code snippet ended before !hide marker above\n} }",
      "syntaxKindCounter": {
        "10": 4,
        "75": 13,
        "130": 1,
        "153": 2,
        "169": 2,
        "193": 1,
        "225": 2,
        "242": 2,
        "243": 2,
        "254": 2,
        "255": 2,
        "256": 1,
        "257": 1,
        "258": 1,
        "281": 3,
        "290": 1
      },
      "fqnsFingerprint": "9ec91ebafa910a22a7863f649334fec2b91dd3bdaa71ee70d8686ad62beb9c3d"
    },
    "cc2b6403326aaf428c8af8bfb7fa1fda07564a364946dbc3acd2ff033bb6d935": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n# Provide a Lambda function that will transform records before delivery, with custom\n# buffering and retry configuration\nlambda_function = lambda_.Function(self, \"Processor\",\n    runtime=lambda_.Runtime.NODEJS_12_X,\n    handler=\"index.handler\",\n    code=lambda_.Code.from_asset(path.join(__dirname, \"process-records\"))\n)\nlambda_processor = firehose.LambdaFunctionProcessor(lambda_function,\n    buffer_interval=Duration.minutes(5),\n    buffer_size=Size.mebibytes(5),\n    retries=5\n)\ns3_destination = destinations.S3Bucket(bucket,\n    processor=lambda_processor\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = new Function(this, \"Processor\", new FunctionProps {\n    Runtime = Runtime.NODEJS_12_X,\n    Handler = \"index.handler\",\n    Code = Code.FromAsset(Join(__dirname, \"process-records\"))\n});\nLambdaFunctionProcessor lambdaProcessor = new LambdaFunctionProcessor(lambdaFunction, new DataProcessorProps {\n    BufferInterval = Duration.Minutes(5),\n    BufferSize = Size.Mebibytes(5),\n    Retries = 5\n});\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Processor = lambdaProcessor\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = Function.Builder.create(this, \"Processor\")\n        .runtime(Runtime.NODEJS_12_X)\n        .handler(\"index.handler\")\n        .code(Code.fromAsset(join(__dirname, \"process-records\")))\n        .build();\nLambdaFunctionProcessor lambdaProcessor = LambdaFunctionProcessor.Builder.create(lambdaFunction)\n        .bufferInterval(Duration.minutes(5))\n        .bufferSize(Size.mebibytes(5))\n        .retries(5)\n        .build();\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .processor(lambdaProcessor)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nlambdaFunction := lambda.NewFunction(this, jsii.String(\"Processor\"), &functionProps{\n\truntime: lambda.runtime_NODEJS_12_X(),\n\thandler: jsii.String(\"index.handler\"),\n\tcode: lambda.code.fromAsset(path.join(__dirname, jsii.String(\"process-records\"))),\n})\nlambdaProcessor := firehose.NewLambdaFunctionProcessor(lambdaFunction, &dataProcessorProps{\n\tbufferInterval: duration.minutes(jsii.Number(5)),\n\tbufferSize: size.mebibytes(jsii.Number(5)),\n\tretries: jsii.Number(5),\n})\ns3Destination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tprocessor: lambdaProcessor,\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\ts3Destination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.aws_lambda.Code",
        "aws-cdk-lib.aws_lambda.Code#fromAsset",
        "aws-cdk-lib.aws_lambda.Function",
        "aws-cdk-lib.aws_lambda.FunctionProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda.Runtime",
        "aws-cdk-lib.aws_lambda.Runtime#NODEJS_12_X",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 3,
        "10": 4,
        "75": 39,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 11,
        "196": 4,
        "197": 4,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "19b84849c80cea41c51f2778c3be6760cd40dc358f5808896db488d18daa930a"
    },
    "576e1610f659f7bcf40843cebc9a475096ff86754156b6612a06e1a631faee13": {
      "translations": {
        "python": {
          "source": "# The code below shows an example of how to instantiate this type.\n# The values are placeholders you should change.\nimport aws_cdk.aws_kinesisfirehose_alpha as kinesisfirehose_alpha\n\ndestination_bind_options = kinesisfirehose_alpha.DestinationBindOptions()",
          "version": "2"
        },
        "csharp": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\n\nDestinationBindOptions destinationBindOptions = new DestinationBindOptions { };",
          "version": "1"
        },
        "java": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\n\nDestinationBindOptions destinationBindOptions = DestinationBindOptions.builder().build();",
          "version": "1"
        },
        "go": {
          "source": "import kinesisfirehose_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"\ndestinationBindOptions := &destinationBindOptions{\n}",
          "version": "1"
        },
        "$": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nconst destinationBindOptions: kinesisfirehose_alpha.DestinationBindOptions = { };",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DestinationBindOptions"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DestinationBindOptions"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\n/// !hide\n// Hoisted imports ended before !hide marker above\nimport { Construct } from \"constructs\";\nclass MyConstruct extends Construct {\nconstructor(scope: Construct, id: string) {\nsuper(scope, id);\n// Code snippet begins after !show marker below\n/// !show\n\nconst destinationBindOptions: kinesisfirehose_alpha.DestinationBindOptions = { };\n/// !hide\n// Code snippet ended before !hide marker above\n} }",
      "syntaxKindCounter": {
        "10": 1,
        "75": 4,
        "153": 1,
        "169": 1,
        "193": 1,
        "225": 1,
        "242": 1,
        "243": 1,
        "254": 1,
        "255": 1,
        "256": 1,
        "290": 1
      },
      "fqnsFingerprint": "8e76b33a43794be4187893cfbe1c43b60e00db27458e96abafc8c7672696f232"
    },
    "70d5556363b587dbf48a847e0298a78ad60aef2ea3a1cf1080a441ad6764e57a": {
      "translations": {
        "python": {
          "source": "# The code below shows an example of how to instantiate this type.\n# The values are placeholders you should change.\nimport aws_cdk.aws_kinesisfirehose_alpha as kinesisfirehose_alpha\nimport constructs as constructs\n\n# dependable: constructs.IDependable\n\ndestination_config = kinesisfirehose_alpha.DestinationConfig(\n    dependables=[dependable],\n    extended_s3_destination_configuration=ExtendedS3DestinationConfigurationProperty(\n        bucket_arn=\"bucketArn\",\n        role_arn=\"roleArn\",\n\n        # the properties below are optional\n        buffering_hints=BufferingHintsProperty(\n            interval_in_seconds=123,\n            size_in_mBs=123\n        ),\n        cloud_watch_logging_options=CloudWatchLoggingOptionsProperty(\n            enabled=False,\n            log_group_name=\"logGroupName\",\n            log_stream_name=\"logStreamName\"\n        ),\n        compression_format=\"compressionFormat\",\n        data_format_conversion_configuration=DataFormatConversionConfigurationProperty(\n            enabled=False,\n            input_format_configuration=InputFormatConfigurationProperty(\n                deserializer=DeserializerProperty(\n                    hive_json_ser_de=HiveJsonSerDeProperty(\n                        timestamp_formats=[\"timestampFormats\"]\n                    ),\n                    open_xJson_ser_de=OpenXJsonSerDeProperty(\n                        case_insensitive=False,\n                        column_to_json_key_mappings={\n                            \"column_to_json_key_mappings_key\": \"columnToJsonKeyMappings\"\n                        },\n                        convert_dots_in_json_keys_to_underscores=False\n                    )\n                )\n            ),\n            output_format_configuration=OutputFormatConfigurationProperty(\n                serializer=SerializerProperty(\n                    orc_ser_de=OrcSerDeProperty(\n                        block_size_bytes=123,\n                        bloom_filter_columns=[\"bloomFilterColumns\"],\n                        bloom_filter_false_positive_probability=123,\n                        compression=\"compression\",\n                        dictionary_key_threshold=123,\n                        enable_padding=False,\n                        format_version=\"formatVersion\",\n                        padding_tolerance=123,\n                        row_index_stride=123,\n                        stripe_size_bytes=123\n                    ),\n                    parquet_ser_de=ParquetSerDeProperty(\n                        block_size_bytes=123,\n                        compression=\"compression\",\n                        enable_dictionary_compression=False,\n                        max_padding_bytes=123,\n                        page_size_bytes=123,\n                        writer_version=\"writerVersion\"\n                    )\n                )\n            ),\n            schema_configuration=SchemaConfigurationProperty(\n                catalog_id=\"catalogId\",\n                database_name=\"databaseName\",\n                region=\"region\",\n                role_arn=\"roleArn\",\n                table_name=\"tableName\",\n                version_id=\"versionId\"\n            )\n        ),\n        dynamic_partitioning_configuration=DynamicPartitioningConfigurationProperty(\n            enabled=False,\n            retry_options=RetryOptionsProperty(\n                duration_in_seconds=123\n            )\n        ),\n        encryption_configuration=EncryptionConfigurationProperty(\n            kms_encryption_config=KMSEncryptionConfigProperty(\n                awskms_key_arn=\"awskmsKeyArn\"\n            ),\n            no_encryption_config=\"noEncryptionConfig\"\n        ),\n        error_output_prefix=\"errorOutputPrefix\",\n        prefix=\"prefix\",\n        processing_configuration=ProcessingConfigurationProperty(\n            enabled=False,\n            processors=[ProcessorProperty(\n                type=\"type\",\n\n                # the properties below are optional\n                parameters=[ProcessorParameterProperty(\n                    parameter_name=\"parameterName\",\n                    parameter_value=\"parameterValue\"\n                )]\n            )]\n        ),\n        s3_backup_configuration=S3DestinationConfigurationProperty(\n            bucket_arn=\"bucketArn\",\n            role_arn=\"roleArn\",\n\n            # the properties below are optional\n            buffering_hints=BufferingHintsProperty(\n                interval_in_seconds=123,\n                size_in_mBs=123\n            ),\n            cloud_watch_logging_options=CloudWatchLoggingOptionsProperty(\n                enabled=False,\n                log_group_name=\"logGroupName\",\n                log_stream_name=\"logStreamName\"\n            ),\n            compression_format=\"compressionFormat\",\n            encryption_configuration=EncryptionConfigurationProperty(\n                kms_encryption_config=KMSEncryptionConfigProperty(\n                    awskms_key_arn=\"awskmsKeyArn\"\n                ),\n                no_encryption_config=\"noEncryptionConfig\"\n            ),\n            error_output_prefix=\"errorOutputPrefix\",\n            prefix=\"prefix\"\n        ),\n        s3_backup_mode=\"s3BackupMode\"\n    )\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Constructs;\n\nIDependable dependable;\nDestinationConfig destinationConfig = new DestinationConfig {\n    Dependables = new [] { dependable },\n    ExtendedS3DestinationConfiguration = new ExtendedS3DestinationConfigurationProperty {\n        BucketArn = \"bucketArn\",\n        RoleArn = \"roleArn\",\n\n        // the properties below are optional\n        BufferingHints = new BufferingHintsProperty {\n            IntervalInSeconds = 123,\n            SizeInMBs = 123\n        },\n        CloudWatchLoggingOptions = new CloudWatchLoggingOptionsProperty {\n            Enabled = false,\n            LogGroupName = \"logGroupName\",\n            LogStreamName = \"logStreamName\"\n        },\n        CompressionFormat = \"compressionFormat\",\n        DataFormatConversionConfiguration = new DataFormatConversionConfigurationProperty {\n            Enabled = false,\n            InputFormatConfiguration = new InputFormatConfigurationProperty {\n                Deserializer = new DeserializerProperty {\n                    HiveJsonSerDe = new HiveJsonSerDeProperty {\n                        TimestampFormats = new [] { \"timestampFormats\" }\n                    },\n                    OpenXJsonSerDe = new OpenXJsonSerDeProperty {\n                        CaseInsensitive = false,\n                        ColumnToJsonKeyMappings = new Dictionary<string, string> {\n                            { \"columnToJsonKeyMappingsKey\", \"columnToJsonKeyMappings\" }\n                        },\n                        ConvertDotsInJsonKeysToUnderscores = false\n                    }\n                }\n            },\n            OutputFormatConfiguration = new OutputFormatConfigurationProperty {\n                Serializer = new SerializerProperty {\n                    OrcSerDe = new OrcSerDeProperty {\n                        BlockSizeBytes = 123,\n                        BloomFilterColumns = new [] { \"bloomFilterColumns\" },\n                        BloomFilterFalsePositiveProbability = 123,\n                        Compression = \"compression\",\n                        DictionaryKeyThreshold = 123,\n                        EnablePadding = false,\n                        FormatVersion = \"formatVersion\",\n                        PaddingTolerance = 123,\n                        RowIndexStride = 123,\n                        StripeSizeBytes = 123\n                    },\n                    ParquetSerDe = new ParquetSerDeProperty {\n                        BlockSizeBytes = 123,\n                        Compression = \"compression\",\n                        EnableDictionaryCompression = false,\n                        MaxPaddingBytes = 123,\n                        PageSizeBytes = 123,\n                        WriterVersion = \"writerVersion\"\n                    }\n                }\n            },\n            SchemaConfiguration = new SchemaConfigurationProperty {\n                CatalogId = \"catalogId\",\n                DatabaseName = \"databaseName\",\n                Region = \"region\",\n                RoleArn = \"roleArn\",\n                TableName = \"tableName\",\n                VersionId = \"versionId\"\n            }\n        },\n        DynamicPartitioningConfiguration = new DynamicPartitioningConfigurationProperty {\n            Enabled = false,\n            RetryOptions = new RetryOptionsProperty {\n                DurationInSeconds = 123\n            }\n        },\n        EncryptionConfiguration = new EncryptionConfigurationProperty {\n            KmsEncryptionConfig = new KMSEncryptionConfigProperty {\n                AwskmsKeyArn = \"awskmsKeyArn\"\n            },\n            NoEncryptionConfig = \"noEncryptionConfig\"\n        },\n        ErrorOutputPrefix = \"errorOutputPrefix\",\n        Prefix = \"prefix\",\n        ProcessingConfiguration = new ProcessingConfigurationProperty {\n            Enabled = false,\n            Processors = new [] { new ProcessorProperty {\n                Type = \"type\",\n\n                // the properties below are optional\n                Parameters = new [] { new ProcessorParameterProperty {\n                    ParameterName = \"parameterName\",\n                    ParameterValue = \"parameterValue\"\n                } }\n            } }\n        },\n        S3BackupConfiguration = new S3DestinationConfigurationProperty {\n            BucketArn = \"bucketArn\",\n            RoleArn = \"roleArn\",\n\n            // the properties below are optional\n            BufferingHints = new BufferingHintsProperty {\n                IntervalInSeconds = 123,\n                SizeInMBs = 123\n            },\n            CloudWatchLoggingOptions = new CloudWatchLoggingOptionsProperty {\n                Enabled = false,\n                LogGroupName = \"logGroupName\",\n                LogStreamName = \"logStreamName\"\n            },\n            CompressionFormat = \"compressionFormat\",\n            EncryptionConfiguration = new EncryptionConfigurationProperty {\n                KmsEncryptionConfig = new KMSEncryptionConfigProperty {\n                    AwskmsKeyArn = \"awskmsKeyArn\"\n                },\n                NoEncryptionConfig = \"noEncryptionConfig\"\n            },\n            ErrorOutputPrefix = \"errorOutputPrefix\",\n            Prefix = \"prefix\"\n        },\n        S3BackupMode = \"s3BackupMode\"\n    }\n};",
          "version": "1"
        },
        "java": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.constructs.*;\n\nIDependable dependable;\n\nDestinationConfig destinationConfig = DestinationConfig.builder()\n        .dependables(List.of(dependable))\n        .extendedS3DestinationConfiguration(ExtendedS3DestinationConfigurationProperty.builder()\n                .bucketArn(\"bucketArn\")\n                .roleArn(\"roleArn\")\n\n                // the properties below are optional\n                .bufferingHints(BufferingHintsProperty.builder()\n                        .intervalInSeconds(123)\n                        .sizeInMBs(123)\n                        .build())\n                .cloudWatchLoggingOptions(CloudWatchLoggingOptionsProperty.builder()\n                        .enabled(false)\n                        .logGroupName(\"logGroupName\")\n                        .logStreamName(\"logStreamName\")\n                        .build())\n                .compressionFormat(\"compressionFormat\")\n                .dataFormatConversionConfiguration(DataFormatConversionConfigurationProperty.builder()\n                        .enabled(false)\n                        .inputFormatConfiguration(InputFormatConfigurationProperty.builder()\n                                .deserializer(DeserializerProperty.builder()\n                                        .hiveJsonSerDe(HiveJsonSerDeProperty.builder()\n                                                .timestampFormats(List.of(\"timestampFormats\"))\n                                                .build())\n                                        .openXJsonSerDe(OpenXJsonSerDeProperty.builder()\n                                                .caseInsensitive(false)\n                                                .columnToJsonKeyMappings(Map.of(\n                                                        \"columnToJsonKeyMappingsKey\", \"columnToJsonKeyMappings\"))\n                                                .convertDotsInJsonKeysToUnderscores(false)\n                                                .build())\n                                        .build())\n                                .build())\n                        .outputFormatConfiguration(OutputFormatConfigurationProperty.builder()\n                                .serializer(SerializerProperty.builder()\n                                        .orcSerDe(OrcSerDeProperty.builder()\n                                                .blockSizeBytes(123)\n                                                .bloomFilterColumns(List.of(\"bloomFilterColumns\"))\n                                                .bloomFilterFalsePositiveProbability(123)\n                                                .compression(\"compression\")\n                                                .dictionaryKeyThreshold(123)\n                                                .enablePadding(false)\n                                                .formatVersion(\"formatVersion\")\n                                                .paddingTolerance(123)\n                                                .rowIndexStride(123)\n                                                .stripeSizeBytes(123)\n                                                .build())\n                                        .parquetSerDe(ParquetSerDeProperty.builder()\n                                                .blockSizeBytes(123)\n                                                .compression(\"compression\")\n                                                .enableDictionaryCompression(false)\n                                                .maxPaddingBytes(123)\n                                                .pageSizeBytes(123)\n                                                .writerVersion(\"writerVersion\")\n                                                .build())\n                                        .build())\n                                .build())\n                        .schemaConfiguration(SchemaConfigurationProperty.builder()\n                                .catalogId(\"catalogId\")\n                                .databaseName(\"databaseName\")\n                                .region(\"region\")\n                                .roleArn(\"roleArn\")\n                                .tableName(\"tableName\")\n                                .versionId(\"versionId\")\n                                .build())\n                        .build())\n                .dynamicPartitioningConfiguration(DynamicPartitioningConfigurationProperty.builder()\n                        .enabled(false)\n                        .retryOptions(RetryOptionsProperty.builder()\n                                .durationInSeconds(123)\n                                .build())\n                        .build())\n                .encryptionConfiguration(EncryptionConfigurationProperty.builder()\n                        .kmsEncryptionConfig(KMSEncryptionConfigProperty.builder()\n                                .awskmsKeyArn(\"awskmsKeyArn\")\n                                .build())\n                        .noEncryptionConfig(\"noEncryptionConfig\")\n                        .build())\n                .errorOutputPrefix(\"errorOutputPrefix\")\n                .prefix(\"prefix\")\n                .processingConfiguration(ProcessingConfigurationProperty.builder()\n                        .enabled(false)\n                        .processors(List.of(ProcessorProperty.builder()\n                                .type(\"type\")\n\n                                // the properties below are optional\n                                .parameters(List.of(ProcessorParameterProperty.builder()\n                                        .parameterName(\"parameterName\")\n                                        .parameterValue(\"parameterValue\")\n                                        .build()))\n                                .build()))\n                        .build())\n                .s3BackupConfiguration(S3DestinationConfigurationProperty.builder()\n                        .bucketArn(\"bucketArn\")\n                        .roleArn(\"roleArn\")\n\n                        // the properties below are optional\n                        .bufferingHints(BufferingHintsProperty.builder()\n                                .intervalInSeconds(123)\n                                .sizeInMBs(123)\n                                .build())\n                        .cloudWatchLoggingOptions(CloudWatchLoggingOptionsProperty.builder()\n                                .enabled(false)\n                                .logGroupName(\"logGroupName\")\n                                .logStreamName(\"logStreamName\")\n                                .build())\n                        .compressionFormat(\"compressionFormat\")\n                        .encryptionConfiguration(EncryptionConfigurationProperty.builder()\n                                .kmsEncryptionConfig(KMSEncryptionConfigProperty.builder()\n                                        .awskmsKeyArn(\"awskmsKeyArn\")\n                                        .build())\n                                .noEncryptionConfig(\"noEncryptionConfig\")\n                                .build())\n                        .errorOutputPrefix(\"errorOutputPrefix\")\n                        .prefix(\"prefix\")\n                        .build())\n                .s3BackupMode(\"s3BackupMode\")\n                .build())\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import kinesisfirehose_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import constructs \"github.com/aws/constructs-go/constructs\"\n\nvar dependable iDependable\ndestinationConfig := &destinationConfig{\n\tdependables: []*iDependable{\n\t\tdependable,\n\t},\n\textendedS3DestinationConfiguration: &extendedS3DestinationConfigurationProperty{\n\t\tbucketArn: jsii.String(\"bucketArn\"),\n\t\troleArn: jsii.String(\"roleArn\"),\n\n\t\t// the properties below are optional\n\t\tbufferingHints: &bufferingHintsProperty{\n\t\t\tintervalInSeconds: jsii.Number(123),\n\t\t\tsizeInMBs: jsii.Number(123),\n\t\t},\n\t\tcloudWatchLoggingOptions: &cloudWatchLoggingOptionsProperty{\n\t\t\tenabled: jsii.Boolean(false),\n\t\t\tlogGroupName: jsii.String(\"logGroupName\"),\n\t\t\tlogStreamName: jsii.String(\"logStreamName\"),\n\t\t},\n\t\tcompressionFormat: jsii.String(\"compressionFormat\"),\n\t\tdataFormatConversionConfiguration: &dataFormatConversionConfigurationProperty{\n\t\t\tenabled: jsii.Boolean(false),\n\t\t\tinputFormatConfiguration: &inputFormatConfigurationProperty{\n\t\t\t\tdeserializer: &deserializerProperty{\n\t\t\t\t\thiveJsonSerDe: &hiveJsonSerDeProperty{\n\t\t\t\t\t\ttimestampFormats: []*string{\n\t\t\t\t\t\t\tjsii.String(\"timestampFormats\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t\topenXJsonSerDe: &openXJsonSerDeProperty{\n\t\t\t\t\t\tcaseInsensitive: jsii.Boolean(false),\n\t\t\t\t\t\tcolumnToJsonKeyMappings: map[string]*string{\n\t\t\t\t\t\t\t\"columnToJsonKeyMappingsKey\": jsii.String(\"columnToJsonKeyMappings\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tconvertDotsInJsonKeysToUnderscores: jsii.Boolean(false),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\toutputFormatConfiguration: &outputFormatConfigurationProperty{\n\t\t\t\tserializer: &serializerProperty{\n\t\t\t\t\torcSerDe: &orcSerDeProperty{\n\t\t\t\t\t\tblockSizeBytes: jsii.Number(123),\n\t\t\t\t\t\tbloomFilterColumns: []*string{\n\t\t\t\t\t\t\tjsii.String(\"bloomFilterColumns\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t\tbloomFilterFalsePositiveProbability: jsii.Number(123),\n\t\t\t\t\t\tcompression: jsii.String(\"compression\"),\n\t\t\t\t\t\tdictionaryKeyThreshold: jsii.Number(123),\n\t\t\t\t\t\tenablePadding: jsii.Boolean(false),\n\t\t\t\t\t\tformatVersion: jsii.String(\"formatVersion\"),\n\t\t\t\t\t\tpaddingTolerance: jsii.Number(123),\n\t\t\t\t\t\trowIndexStride: jsii.Number(123),\n\t\t\t\t\t\tstripeSizeBytes: jsii.Number(123),\n\t\t\t\t\t},\n\t\t\t\t\tparquetSerDe: &parquetSerDeProperty{\n\t\t\t\t\t\tblockSizeBytes: jsii.Number(123),\n\t\t\t\t\t\tcompression: jsii.String(\"compression\"),\n\t\t\t\t\t\tenableDictionaryCompression: jsii.Boolean(false),\n\t\t\t\t\t\tmaxPaddingBytes: jsii.Number(123),\n\t\t\t\t\t\tpageSizeBytes: jsii.Number(123),\n\t\t\t\t\t\twriterVersion: jsii.String(\"writerVersion\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\tschemaConfiguration: &schemaConfigurationProperty{\n\t\t\t\tcatalogId: jsii.String(\"catalogId\"),\n\t\t\t\tdatabaseName: jsii.String(\"databaseName\"),\n\t\t\t\tregion: jsii.String(\"region\"),\n\t\t\t\troleArn: jsii.String(\"roleArn\"),\n\t\t\t\ttableName: jsii.String(\"tableName\"),\n\t\t\t\tversionId: jsii.String(\"versionId\"),\n\t\t\t},\n\t\t},\n\t\tdynamicPartitioningConfiguration: &dynamicPartitioningConfigurationProperty{\n\t\t\tenabled: jsii.Boolean(false),\n\t\t\tretryOptions: &retryOptionsProperty{\n\t\t\t\tdurationInSeconds: jsii.Number(123),\n\t\t\t},\n\t\t},\n\t\tencryptionConfiguration: &encryptionConfigurationProperty{\n\t\t\tkmsEncryptionConfig: &kMSEncryptionConfigProperty{\n\t\t\t\tawskmsKeyArn: jsii.String(\"awskmsKeyArn\"),\n\t\t\t},\n\t\t\tnoEncryptionConfig: jsii.String(\"noEncryptionConfig\"),\n\t\t},\n\t\terrorOutputPrefix: jsii.String(\"errorOutputPrefix\"),\n\t\tprefix: jsii.String(\"prefix\"),\n\t\tprocessingConfiguration: &processingConfigurationProperty{\n\t\t\tenabled: jsii.Boolean(false),\n\t\t\tprocessors: []interface{}{\n\t\t\t\t&processorProperty{\n\t\t\t\t\ttype: jsii.String(\"type\"),\n\n\t\t\t\t\t// the properties below are optional\n\t\t\t\t\tparameters: []interface{}{\n\t\t\t\t\t\t&processorParameterProperty{\n\t\t\t\t\t\t\tparameterName: jsii.String(\"parameterName\"),\n\t\t\t\t\t\t\tparameterValue: jsii.String(\"parameterValue\"),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\ts3BackupConfiguration: &s3DestinationConfigurationProperty{\n\t\t\tbucketArn: jsii.String(\"bucketArn\"),\n\t\t\troleArn: jsii.String(\"roleArn\"),\n\n\t\t\t// the properties below are optional\n\t\t\tbufferingHints: &bufferingHintsProperty{\n\t\t\t\tintervalInSeconds: jsii.Number(123),\n\t\t\t\tsizeInMBs: jsii.Number(123),\n\t\t\t},\n\t\t\tcloudWatchLoggingOptions: &cloudWatchLoggingOptionsProperty{\n\t\t\t\tenabled: jsii.Boolean(false),\n\t\t\t\tlogGroupName: jsii.String(\"logGroupName\"),\n\t\t\t\tlogStreamName: jsii.String(\"logStreamName\"),\n\t\t\t},\n\t\t\tcompressionFormat: jsii.String(\"compressionFormat\"),\n\t\t\tencryptionConfiguration: &encryptionConfigurationProperty{\n\t\t\t\tkmsEncryptionConfig: &kMSEncryptionConfigProperty{\n\t\t\t\t\tawskmsKeyArn: jsii.String(\"awskmsKeyArn\"),\n\t\t\t\t},\n\t\t\t\tnoEncryptionConfig: jsii.String(\"noEncryptionConfig\"),\n\t\t\t},\n\t\t\terrorOutputPrefix: jsii.String(\"errorOutputPrefix\"),\n\t\t\tprefix: jsii.String(\"prefix\"),\n\t\t},\n\t\ts3BackupMode: jsii.String(\"s3BackupMode\"),\n\t},\n}",
          "version": "1"
        },
        "$": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as constructs from 'constructs';\n\ndeclare const dependable: constructs.IDependable;\nconst destinationConfig: kinesisfirehose_alpha.DestinationConfig = {\n  dependables: [dependable],\n  extendedS3DestinationConfiguration: {\n    bucketArn: 'bucketArn',\n    roleArn: 'roleArn',\n\n    // the properties below are optional\n    bufferingHints: {\n      intervalInSeconds: 123,\n      sizeInMBs: 123,\n    },\n    cloudWatchLoggingOptions: {\n      enabled: false,\n      logGroupName: 'logGroupName',\n      logStreamName: 'logStreamName',\n    },\n    compressionFormat: 'compressionFormat',\n    dataFormatConversionConfiguration: {\n      enabled: false,\n      inputFormatConfiguration: {\n        deserializer: {\n          hiveJsonSerDe: {\n            timestampFormats: ['timestampFormats'],\n          },\n          openXJsonSerDe: {\n            caseInsensitive: false,\n            columnToJsonKeyMappings: {\n              columnToJsonKeyMappingsKey: 'columnToJsonKeyMappings',\n            },\n            convertDotsInJsonKeysToUnderscores: false,\n          },\n        },\n      },\n      outputFormatConfiguration: {\n        serializer: {\n          orcSerDe: {\n            blockSizeBytes: 123,\n            bloomFilterColumns: ['bloomFilterColumns'],\n            bloomFilterFalsePositiveProbability: 123,\n            compression: 'compression',\n            dictionaryKeyThreshold: 123,\n            enablePadding: false,\n            formatVersion: 'formatVersion',\n            paddingTolerance: 123,\n            rowIndexStride: 123,\n            stripeSizeBytes: 123,\n          },\n          parquetSerDe: {\n            blockSizeBytes: 123,\n            compression: 'compression',\n            enableDictionaryCompression: false,\n            maxPaddingBytes: 123,\n            pageSizeBytes: 123,\n            writerVersion: 'writerVersion',\n          },\n        },\n      },\n      schemaConfiguration: {\n        catalogId: 'catalogId',\n        databaseName: 'databaseName',\n        region: 'region',\n        roleArn: 'roleArn',\n        tableName: 'tableName',\n        versionId: 'versionId',\n      },\n    },\n    dynamicPartitioningConfiguration: {\n      enabled: false,\n      retryOptions: {\n        durationInSeconds: 123,\n      },\n    },\n    encryptionConfiguration: {\n      kmsEncryptionConfig: {\n        awskmsKeyArn: 'awskmsKeyArn',\n      },\n      noEncryptionConfig: 'noEncryptionConfig',\n    },\n    errorOutputPrefix: 'errorOutputPrefix',\n    prefix: 'prefix',\n    processingConfiguration: {\n      enabled: false,\n      processors: [{\n        type: 'type',\n\n        // the properties below are optional\n        parameters: [{\n          parameterName: 'parameterName',\n          parameterValue: 'parameterValue',\n        }],\n      }],\n    },\n    s3BackupConfiguration: {\n      bucketArn: 'bucketArn',\n      roleArn: 'roleArn',\n\n      // the properties below are optional\n      bufferingHints: {\n        intervalInSeconds: 123,\n        sizeInMBs: 123,\n      },\n      cloudWatchLoggingOptions: {\n        enabled: false,\n        logGroupName: 'logGroupName',\n        logStreamName: 'logStreamName',\n      },\n      compressionFormat: 'compressionFormat',\n      encryptionConfiguration: {\n        kmsEncryptionConfig: {\n          awskmsKeyArn: 'awskmsKeyArn',\n        },\n        noEncryptionConfig: 'noEncryptionConfig',\n      },\n      errorOutputPrefix: 'errorOutputPrefix',\n      prefix: 'prefix',\n    },\n    s3BackupMode: 's3BackupMode',\n  },\n};",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.DestinationConfig"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DestinationConfig",
        "aws-cdk-lib.aws_kinesisfirehose.CfnDeliveryStream.ExtendedS3DestinationConfigurationProperty"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as constructs from 'constructs';\n\ndeclare const dependable: constructs.IDependable;\n/// !hide\n// Hoisted imports ended before !hide marker above\nimport { Construct } from \"constructs\";\nclass MyConstruct extends Construct {\nconstructor(scope: Construct, id: string) {\nsuper(scope, id);\n// Code snippet begins after !show marker below\n/// !show\n\nconst destinationConfig: kinesisfirehose_alpha.DestinationConfig = {\n  dependables: [dependable],\n  extendedS3DestinationConfiguration: {\n    bucketArn: 'bucketArn',\n    roleArn: 'roleArn',\n\n    // the properties below are optional\n    bufferingHints: {\n      intervalInSeconds: 123,\n      sizeInMBs: 123,\n    },\n    cloudWatchLoggingOptions: {\n      enabled: false,\n      logGroupName: 'logGroupName',\n      logStreamName: 'logStreamName',\n    },\n    compressionFormat: 'compressionFormat',\n    dataFormatConversionConfiguration: {\n      enabled: false,\n      inputFormatConfiguration: {\n        deserializer: {\n          hiveJsonSerDe: {\n            timestampFormats: ['timestampFormats'],\n          },\n          openXJsonSerDe: {\n            caseInsensitive: false,\n            columnToJsonKeyMappings: {\n              columnToJsonKeyMappingsKey: 'columnToJsonKeyMappings',\n            },\n            convertDotsInJsonKeysToUnderscores: false,\n          },\n        },\n      },\n      outputFormatConfiguration: {\n        serializer: {\n          orcSerDe: {\n            blockSizeBytes: 123,\n            bloomFilterColumns: ['bloomFilterColumns'],\n            bloomFilterFalsePositiveProbability: 123,\n            compression: 'compression',\n            dictionaryKeyThreshold: 123,\n            enablePadding: false,\n            formatVersion: 'formatVersion',\n            paddingTolerance: 123,\n            rowIndexStride: 123,\n            stripeSizeBytes: 123,\n          },\n          parquetSerDe: {\n            blockSizeBytes: 123,\n            compression: 'compression',\n            enableDictionaryCompression: false,\n            maxPaddingBytes: 123,\n            pageSizeBytes: 123,\n            writerVersion: 'writerVersion',\n          },\n        },\n      },\n      schemaConfiguration: {\n        catalogId: 'catalogId',\n        databaseName: 'databaseName',\n        region: 'region',\n        roleArn: 'roleArn',\n        tableName: 'tableName',\n        versionId: 'versionId',\n      },\n    },\n    dynamicPartitioningConfiguration: {\n      enabled: false,\n      retryOptions: {\n        durationInSeconds: 123,\n      },\n    },\n    encryptionConfiguration: {\n      kmsEncryptionConfig: {\n        awskmsKeyArn: 'awskmsKeyArn',\n      },\n      noEncryptionConfig: 'noEncryptionConfig',\n    },\n    errorOutputPrefix: 'errorOutputPrefix',\n    prefix: 'prefix',\n    processingConfiguration: {\n      enabled: false,\n      processors: [{\n        type: 'type',\n\n        // the properties below are optional\n        parameters: [{\n          parameterName: 'parameterName',\n          parameterValue: 'parameterValue',\n        }],\n      }],\n    },\n    s3BackupConfiguration: {\n      bucketArn: 'bucketArn',\n      roleArn: 'roleArn',\n\n      // the properties below are optional\n      bufferingHints: {\n        intervalInSeconds: 123,\n        sizeInMBs: 123,\n      },\n      cloudWatchLoggingOptions: {\n        enabled: false,\n        logGroupName: 'logGroupName',\n        logStreamName: 'logStreamName',\n      },\n      compressionFormat: 'compressionFormat',\n      encryptionConfiguration: {\n        kmsEncryptionConfig: {\n          awskmsKeyArn: 'awskmsKeyArn',\n        },\n        noEncryptionConfig: 'noEncryptionConfig',\n      },\n      errorOutputPrefix: 'errorOutputPrefix',\n      prefix: 'prefix',\n    },\n    s3BackupMode: 's3BackupMode',\n  },\n};\n/// !hide\n// Code snippet ended before !hide marker above\n} }",
      "syntaxKindCounter": {
        "8": 14,
        "10": 37,
        "75": 94,
        "91": 9,
        "130": 1,
        "153": 2,
        "169": 2,
        "192": 5,
        "193": 27,
        "225": 2,
        "242": 2,
        "243": 2,
        "254": 2,
        "255": 2,
        "256": 2,
        "281": 85,
        "290": 1
      },
      "fqnsFingerprint": "98f754d91712adf0fda0be1b1c2ae6f4b1c4b4e3ba21c934ca0ef85bb88871c1"
    },
    "d2a685978c9df6cd77545c37c678e8db05e4f29b98d71faea7588925b128235f": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose_alpha as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "2"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "go": {
          "source": "import path \"github.com/aws-samples/dummy/path\"import firehose \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import kms \"github.com/aws/aws-cdk-go/awscdk\"import lambdanodejs \"github.com/aws/aws-cdk-go/awscdk\"import logs \"github.com/aws/aws-cdk-go/awscdk\"import s3 \"github.com/aws/aws-cdk-go/awscdk\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import destinations \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"\n\napp := cdk.NewApp()\n\nstack := cdk.NewStack(app, jsii.String(\"aws-cdk-firehose-delivery-stream-s3-all-properties\"))\n\nbucket := s3.NewBucket(stack, jsii.String(\"Bucket\"), &bucketProps{\n\tremovalPolicy: cdk.removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\n\nbackupBucket := s3.NewBucket(stack, jsii.String(\"BackupBucket\"), &bucketProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\nlogGroup := logs.NewLogGroup(stack, jsii.String(\"LogGroup\"), &logGroupProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\ndataProcessorFunction := lambdanodejs.NewNodejsFunction(stack, jsii.String(\"DataProcessorFunction\"), &nodejsFunctionProps{\n\tentry: path.join(__dirname, jsii.String(\"lambda-data-processor.js\")),\n\ttimeout: cdk.duration.minutes(jsii.Number(1)),\n})\n\nprocessor := firehose.NewLambdaFunctionProcessor(dataProcessorFunction, &dataProcessorProps{\n\tbufferInterval: cdk.*duration.seconds(jsii.Number(60)),\n\tbufferSize: cdk.size.mebibytes(jsii.Number(1)),\n\tretries: jsii.Number(1),\n})\n\nkey := kms.NewKey(stack, jsii.String(\"Key\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nbackupKey := kms.NewKey(stack, jsii.String(\"BackupKey\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nfirehose.NewDeliveryStream(stack, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\tlogging: jsii.Boolean(true),\n\t\t\tlogGroup: logGroup,\n\t\t\tprocessor: processor,\n\t\t\tcompression: destinations.compression_GZIP(),\n\t\t\tdataOutputPrefix: jsii.String(\"regularPrefix\"),\n\t\t\terrorOutputPrefix: jsii.String(\"errorPrefix\"),\n\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\tencryptionKey: key,\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.backupMode_ALL,\n\t\t\t\tbucket: backupBucket,\n\t\t\t\tcompression: destinations.*compression_ZIP(),\n\t\t\t\tdataOutputPrefix: jsii.String(\"backupPrefix\"),\n\t\t\t\terrorOutputPrefix: jsii.String(\"backupErrorPrefix\"),\n\t\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\t\tencryptionKey: backupKey,\n\t\t\t},\n\t\t}),\n\t},\n})\n\napp.synth()",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.App",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Duration#seconds",
        "aws-cdk-lib.RemovalPolicy",
        "aws-cdk-lib.RemovalPolicy#DESTROY",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.Stack",
        "aws-cdk-lib.Stage#synth",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_kms.Key",
        "aws-cdk-lib.aws_kms.KeyProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunctionProps",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_logs.LogGroup",
        "aws-cdk-lib.aws_logs.LogGroupProps",
        "aws-cdk-lib.aws_s3.Bucket",
        "aws-cdk-lib.aws_s3.BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as lambdanodejs from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cdk from 'aws-cdk-lib';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "47f33d4b0ee02f2364ebedbffe5a9fe2034492885858b06995f76713786ae1eb"
    },
    "78048cb78feada8c4db16377e63dbd3d39ce1ec18b493e0226a27b88009d4ff5": {
      "translations": {
        "python": {
          "source": "# destination: firehose.IDestination\n# SSE with an customer-managed CMK that is explicitly specified\n# key: kms.Key\n\n\n# SSE with an AWS-owned CMK\nfirehose.DeliveryStream(self, \"Delivery Stream AWS Owned\",\n    encryption=firehose.StreamEncryption.AWS_OWNED,\n    destinations=[destination]\n)\n# SSE with an customer-managed CMK that is created automatically by the CDK\nfirehose.DeliveryStream(self, \"Delivery Stream Implicit Customer Managed\",\n    encryption=firehose.StreamEncryption.CUSTOMER_MANAGED,\n    destinations=[destination]\n)\nfirehose.DeliveryStream(self, \"Delivery Stream Explicit Customer Managed\",\n    encryption_key=key,\n    destinations=[destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "IDestination destination;\n// SSE with an customer-managed CMK that is explicitly specified\nKey key;\n\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nnew DeliveryStream(this, \"Delivery Stream AWS Owned\", new DeliveryStreamProps {\n    Encryption = StreamEncryption.AWS_OWNED,\n    Destinations = new [] { destination }\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew DeliveryStream(this, \"Delivery Stream Implicit Customer Managed\", new DeliveryStreamProps {\n    Encryption = StreamEncryption.CUSTOMER_MANAGED,\n    Destinations = new [] { destination }\n});\nnew DeliveryStream(this, \"Delivery Stream Explicit Customer Managed\", new DeliveryStreamProps {\n    EncryptionKey = key,\n    Destinations = new [] { destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "IDestination destination;\n// SSE with an customer-managed CMK that is explicitly specified\nKey key;\n\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nDeliveryStream.Builder.create(this, \"Delivery Stream AWS Owned\")\n        .encryption(StreamEncryption.AWS_OWNED)\n        .destinations(List.of(destination))\n        .build();\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nDeliveryStream.Builder.create(this, \"Delivery Stream Implicit Customer Managed\")\n        .encryption(StreamEncryption.CUSTOMER_MANAGED)\n        .destinations(List.of(destination))\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream Explicit Customer Managed\")\n        .encryptionKey(key)\n        .destinations(List.of(destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var destination iDestination\n// SSE with an customer-managed CMK that is explicitly specified\nvar key key\n\n// SSE with an AWS-owned CMK\n// SSE with an AWS-owned CMK\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream AWS Owned\"), &deliveryStreamProps{\n\tencryption: firehose.streamEncryption_AWS_OWNED,\n\tdestinations: []*iDestination{\n\t\tdestination,\n\t},\n})\n// SSE with an customer-managed CMK that is created automatically by the CDK\n// SSE with an customer-managed CMK that is created automatically by the CDK\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream Implicit Customer Managed\"), &deliveryStreamProps{\n\tencryption: firehose.*streamEncryption_CUSTOMER_MANAGED,\n\tdestinations: []*iDestination{\n\t\tdestination,\n\t},\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream Explicit Customer Managed\"), &deliveryStreamProps{\n\tencryptionKey: key,\n\tdestinations: []*iDestination{\n\t\tdestination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "declare const destination: firehose.IDestination;\n\n// SSE with an AWS-owned CMK\nnew firehose.DeliveryStream(this, 'Delivery Stream AWS Owned', {\n  encryption: firehose.StreamEncryption.AWS_OWNED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew firehose.DeliveryStream(this, 'Delivery Stream Implicit Customer Managed', {\n  encryption: firehose.StreamEncryption.CUSTOMER_MANAGED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is explicitly specified\ndeclare const key: kms.Key;\nnew firehose.DeliveryStream(this, 'Delivery Stream Explicit Customer Managed', {\n  encryptionKey: key,\n  destinations: [destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-alpha.StreamEncryption"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.StreamEncryption",
        "@aws-cdk/aws-kinesisfirehose-alpha.StreamEncryption#AWS_OWNED",
        "@aws-cdk/aws-kinesisfirehose-alpha.StreamEncryption#CUSTOMER_MANAGED",
        "aws-cdk-lib.aws_kms.IKey"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\ndeclare const destination: firehose.IDestination;\n// SSE with an customer-managed CMK that is explicitly specified\ndeclare const key: kms.Key;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n\n\n// SSE with an AWS-owned CMK\nnew firehose.DeliveryStream(this, 'Delivery Stream AWS Owned', {\n  encryption: firehose.StreamEncryption.AWS_OWNED,\n  destinations: [destination],\n});\n// SSE with an customer-managed CMK that is created automatically by the CDK\nnew firehose.DeliveryStream(this, 'Delivery Stream Implicit Customer Managed', {\n  encryption: firehose.StreamEncryption.CUSTOMER_MANAGED,\n  destinations: [destination],\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream Explicit Customer Managed', {\n  encryptionKey: key,\n  destinations: [destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "10": 3,
        "75": 28,
        "104": 3,
        "130": 2,
        "153": 2,
        "169": 2,
        "192": 3,
        "193": 3,
        "194": 7,
        "197": 3,
        "225": 2,
        "226": 3,
        "242": 2,
        "243": 2,
        "281": 6,
        "290": 1
      },
      "fqnsFingerprint": "dffc7ed2e88ba7a52da7841a27166fe5a43a7aa26af1c1479892338313b22505"
    }
  }
}
