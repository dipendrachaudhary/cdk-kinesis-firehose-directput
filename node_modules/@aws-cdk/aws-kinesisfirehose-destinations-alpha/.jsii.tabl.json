{
  "version": "2",
  "toolVersion": "1.57.0",
  "snippets": {
    "1dd28f9eb0f3615f82c5a1c9a132f803ed7b30a72f1ca3a1e287f9fe825dfc2d": {
      "translations": {
        "python": {
          "source": "import aws_cdk.aws_kinesisfirehose_destinations_alpha as destinations",
          "version": "2"
        },
        "csharp": {
          "source": "using Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;",
          "version": "1"
        },
        "java": {
          "source": "import software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;",
          "version": "1"
        },
        "go": {
          "source": "import destinations \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"",
          "version": "1"
        },
        "$": {
          "source": "import * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "moduleReadme",
          "moduleFqn": "@aws-cdk/aws-kinesisfirehose-destinations-alpha"
        },
        "field": {
          "field": "markdown",
          "line": 24
        }
      },
      "didCompile": true,
      "fqnsReferenced": [],
      "fullSource": "import * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';",
      "syntaxKindCounter": {
        "10": 1,
        "75": 1,
        "254": 1,
        "255": 1,
        "256": 1,
        "290": 1
      },
      "fqnsFingerprint": "e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"
    },
    "b7d89b6ab863350c7e3e1331f86bcacda30f70daeaaa7e9a089b0023cc7003ab": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose_alpha as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "2"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "go": {
          "source": "import path \"github.com/aws-samples/dummy/path\"import firehose \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import kms \"github.com/aws/aws-cdk-go/awscdk\"import lambdanodejs \"github.com/aws/aws-cdk-go/awscdk\"import logs \"github.com/aws/aws-cdk-go/awscdk\"import s3 \"github.com/aws/aws-cdk-go/awscdk\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import destinations \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"\n\napp := cdk.NewApp()\n\nstack := cdk.NewStack(app, jsii.String(\"aws-cdk-firehose-delivery-stream-s3-all-properties\"))\n\nbucket := s3.NewBucket(stack, jsii.String(\"Bucket\"), &bucketProps{\n\tremovalPolicy: cdk.removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\n\nbackupBucket := s3.NewBucket(stack, jsii.String(\"BackupBucket\"), &bucketProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\nlogGroup := logs.NewLogGroup(stack, jsii.String(\"LogGroup\"), &logGroupProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\ndataProcessorFunction := lambdanodejs.NewNodejsFunction(stack, jsii.String(\"DataProcessorFunction\"), &nodejsFunctionProps{\n\tentry: path.join(__dirname, jsii.String(\"lambda-data-processor.js\")),\n\ttimeout: cdk.duration.minutes(jsii.Number(1)),\n})\n\nprocessor := firehose.NewLambdaFunctionProcessor(dataProcessorFunction, &dataProcessorProps{\n\tbufferInterval: cdk.*duration.seconds(jsii.Number(60)),\n\tbufferSize: cdk.size.mebibytes(jsii.Number(1)),\n\tretries: jsii.Number(1),\n})\n\nkey := kms.NewKey(stack, jsii.String(\"Key\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nbackupKey := kms.NewKey(stack, jsii.String(\"BackupKey\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nfirehose.NewDeliveryStream(stack, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\tlogging: jsii.Boolean(true),\n\t\t\tlogGroup: logGroup,\n\t\t\tprocessor: processor,\n\t\t\tcompression: destinations.compression_GZIP(),\n\t\t\tdataOutputPrefix: jsii.String(\"regularPrefix\"),\n\t\t\terrorOutputPrefix: jsii.String(\"errorPrefix\"),\n\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\tencryptionKey: key,\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.backupMode_ALL,\n\t\t\t\tbucket: backupBucket,\n\t\t\t\tcompression: destinations.*compression_ZIP(),\n\t\t\t\tdataOutputPrefix: jsii.String(\"backupPrefix\"),\n\t\t\t\terrorOutputPrefix: jsii.String(\"backupErrorPrefix\"),\n\t\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\t\tencryptionKey: backupKey,\n\t\t\t},\n\t\t}),\n\t},\n})\n\napp.synth()",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.App",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Duration#seconds",
        "aws-cdk-lib.RemovalPolicy",
        "aws-cdk-lib.RemovalPolicy#DESTROY",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.Stack",
        "aws-cdk-lib.Stage#synth",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_kms.Key",
        "aws-cdk-lib.aws_kms.KeyProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunctionProps",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_logs.LogGroup",
        "aws-cdk-lib.aws_logs.LogGroupProps",
        "aws-cdk-lib.aws_s3.Bucket",
        "aws-cdk-lib.aws_s3.BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as lambdanodejs from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cdk from 'aws-cdk-lib';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "47f33d4b0ee02f2364ebedbffe5a9fe2034492885858b06995f76713786ae1eb"
    },
    "ec5ef3e9af943e3495d036536a3ea77c717559ae5e4d74db6bbbcfc5e1acb0e7": {
      "translations": {
        "python": {
          "source": "# The code below shows an example of how to instantiate this type.\n# The values are placeholders you should change.\nimport aws_cdk.aws_kinesisfirehose_alpha as kinesisfirehose_alpha\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as kinesisfirehose_destinations_alpha\nimport aws_cdk as cdk\nfrom aws_cdk import aws_iam as iam\nfrom aws_cdk import aws_kms as kms\nfrom aws_cdk import aws_logs as logs\nfrom aws_cdk import aws_s3 as s3\n\n# bucket: s3.Bucket\n# compression: kinesisfirehose_destinations_alpha.Compression\n# data_processor: kinesisfirehose_alpha.IDataProcessor\n# key: kms.Key\n# log_group: logs.LogGroup\n# role: iam.Role\n# size: cdk.Size\n\ncommon_destination_props = kinesisfirehose_destinations_alpha.CommonDestinationProps(\n    logging=False,\n    log_group=log_group,\n    processor=data_processor,\n    role=role,\n    s3_backup=kinesisfirehose_destinations_alpha.DestinationS3BackupProps(\n        bucket=bucket,\n        buffering_interval=cdk.Duration.minutes(30),\n        buffering_size=size,\n        compression=compression,\n        data_output_prefix=\"dataOutputPrefix\",\n        encryption_key=key,\n        error_output_prefix=\"errorOutputPrefix\",\n        logging=False,\n        log_group=log_group,\n        mode=kinesisfirehose_destinations_alpha.BackupMode.ALL\n    )\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.IAM;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\n\nBucket bucket;\nCompression compression;\nIDataProcessor dataProcessor;\nKey key;\nLogGroup logGroup;\nRole role;\nSize size;\n\nCommonDestinationProps commonDestinationProps = new CommonDestinationProps {\n    Logging = false,\n    LogGroup = logGroup,\n    Processor = dataProcessor,\n    Role = role,\n    S3Backup = new DestinationS3BackupProps {\n        Bucket = bucket,\n        BufferingInterval = Duration.Minutes(30),\n        BufferingSize = size,\n        Compression = compression,\n        DataOutputPrefix = \"dataOutputPrefix\",\n        EncryptionKey = key,\n        ErrorOutputPrefix = \"errorOutputPrefix\",\n        Logging = false,\n        LogGroup = logGroup,\n        Mode = BackupMode.ALL\n    }\n};",
          "version": "1"
        },
        "java": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.iam.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\n\nBucket bucket;\nCompression compression;\nIDataProcessor dataProcessor;\nKey key;\nLogGroup logGroup;\nRole role;\nSize size;\n\nCommonDestinationProps commonDestinationProps = CommonDestinationProps.builder()\n        .logging(false)\n        .logGroup(logGroup)\n        .processor(dataProcessor)\n        .role(role)\n        .s3Backup(DestinationS3BackupProps.builder()\n                .bucket(bucket)\n                .bufferingInterval(Duration.minutes(30))\n                .bufferingSize(size)\n                .compression(compression)\n                .dataOutputPrefix(\"dataOutputPrefix\")\n                .encryptionKey(key)\n                .errorOutputPrefix(\"errorOutputPrefix\")\n                .logging(false)\n                .logGroup(logGroup)\n                .mode(BackupMode.ALL)\n                .build())\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import kinesisfirehose_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import kinesisfirehose_destinations_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import awscdk \"github.com/aws/aws-cdk-go/awscdk\"import iam \"github.com/aws/aws-cdk-go/awscdk/aws_iam\"import awscdk \"github.com/aws/aws-cdk-go/awscdk\"import kms \"github.com/aws/aws-cdk-go/awscdk/aws_kms\"import awscdk \"github.com/aws/aws-cdk-go/awscdk\"import logs \"github.com/aws/aws-cdk-go/awscdk/aws_logs\"import awscdk \"github.com/aws/aws-cdk-go/awscdk\"import s3 \"github.com/aws/aws-cdk-go/awscdk/aws_s3\"\n\nvar bucket bucket\nvar compression compression\nvar dataProcessor iDataProcessor\nvar key key\nvar logGroup logGroup\nvar role role\nvar size size\ncommonDestinationProps := &commonDestinationProps{\n\tlogging: jsii.Boolean(false),\n\tlogGroup: logGroup,\n\tprocessor: dataProcessor,\n\trole: role,\n\ts3Backup: &destinationS3BackupProps{\n\t\tbucket: bucket,\n\t\tbufferingInterval: cdk.duration.minutes(jsii.Number(30)),\n\t\tbufferingSize: size,\n\t\tcompression: compression,\n\t\tdataOutputPrefix: jsii.String(\"dataOutputPrefix\"),\n\t\tencryptionKey: key,\n\t\terrorOutputPrefix: jsii.String(\"errorOutputPrefix\"),\n\t\tlogging: jsii.Boolean(false),\n\t\tlogGroup: logGroup,\n\t\tmode: kinesisfirehose_destinations_alpha.backupMode_ALL,\n\t},\n}",
          "version": "1"
        },
        "$": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesisfirehose_destinations_alpha from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as cdk from 'aws-cdk-lib';\nimport { aws_iam as iam } from 'aws-cdk-lib';\nimport { aws_kms as kms } from 'aws-cdk-lib';\nimport { aws_logs as logs } from 'aws-cdk-lib';\nimport { aws_s3 as s3 } from 'aws-cdk-lib';\n\ndeclare const bucket: s3.Bucket;\ndeclare const compression: kinesisfirehose_destinations_alpha.Compression;\ndeclare const dataProcessor: kinesisfirehose_alpha.IDataProcessor;\ndeclare const key: kms.Key;\ndeclare const logGroup: logs.LogGroup;\ndeclare const role: iam.Role;\ndeclare const size: cdk.Size;\nconst commonDestinationProps: kinesisfirehose_destinations_alpha.CommonDestinationProps = {\n  logging: false,\n  logGroup: logGroup,\n  processor: dataProcessor,\n  role: role,\n  s3Backup: {\n    bucket: bucket,\n    bufferingInterval: cdk.Duration.minutes(30),\n    bufferingSize: size,\n    compression: compression,\n    dataOutputPrefix: 'dataOutputPrefix',\n    encryptionKey: key,\n    errorOutputPrefix: 'errorOutputPrefix',\n    logging: false,\n    logGroup: logGroup,\n    mode: kinesisfirehose_destinations_alpha.BackupMode.ALL,\n  },\n};",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-destinations-alpha.CommonDestinationProps"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.CommonDestinationProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.aws_iam.IRole",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_alpha from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesisfirehose_destinations_alpha from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as cdk from 'aws-cdk-lib';\nimport { aws_iam as iam } from 'aws-cdk-lib';\nimport { aws_kms as kms } from 'aws-cdk-lib';\nimport { aws_logs as logs } from 'aws-cdk-lib';\nimport { aws_s3 as s3 } from 'aws-cdk-lib';\n\ndeclare const bucket: s3.Bucket;\ndeclare const compression: kinesisfirehose_destinations_alpha.Compression;\ndeclare const dataProcessor: kinesisfirehose_alpha.IDataProcessor;\ndeclare const key: kms.Key;\ndeclare const logGroup: logs.LogGroup;\ndeclare const role: iam.Role;\ndeclare const size: cdk.Size;\n/// !hide\n// Hoisted imports ended before !hide marker above\nimport { Construct } from \"constructs\";\nclass MyConstruct extends Construct {\nconstructor(scope: Construct, id: string) {\nsuper(scope, id);\n// Code snippet begins after !show marker below\n/// !show\n\nconst commonDestinationProps: kinesisfirehose_destinations_alpha.CommonDestinationProps = {\n  logging: false,\n  logGroup: logGroup,\n  processor: dataProcessor,\n  role: role,\n  s3Backup: {\n    bucket: bucket,\n    bufferingInterval: cdk.Duration.minutes(30),\n    bufferingSize: size,\n    compression: compression,\n    dataOutputPrefix: 'dataOutputPrefix',\n    encryptionKey: key,\n    errorOutputPrefix: 'errorOutputPrefix',\n    logging: false,\n    logGroup: logGroup,\n    mode: kinesisfirehose_destinations_alpha.BackupMode.ALL,\n  },\n};\n/// !hide\n// Code snippet ended before !hide marker above\n} }",
      "syntaxKindCounter": {
        "8": 1,
        "10": 9,
        "75": 64,
        "91": 2,
        "130": 7,
        "153": 8,
        "169": 8,
        "193": 2,
        "194": 4,
        "196": 1,
        "225": 8,
        "242": 8,
        "243": 8,
        "254": 7,
        "255": 7,
        "256": 3,
        "257": 4,
        "258": 4,
        "281": 15,
        "290": 1
      },
      "fqnsFingerprint": "a9940e70e23cb8fa650edc084ac7841a8775336bf9886d44bb94d0f54576da13"
    },
    "230df0d55556066934830cb390fb601aa25635de72ef7a07d2cf0b16451d594e": {
      "translations": {
        "python": {
          "source": "# The code below shows an example of how to instantiate this type.\n# The values are placeholders you should change.\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as kinesisfirehose_destinations_alpha\nimport aws_cdk as cdk\nfrom aws_cdk import aws_kms as kms\n\n# compression: kinesisfirehose_destinations_alpha.Compression\n# key: kms.Key\n# size: cdk.Size\n\ncommon_destination_s3_props = kinesisfirehose_destinations_alpha.CommonDestinationS3Props(\n    buffering_interval=cdk.Duration.minutes(30),\n    buffering_size=size,\n    compression=compression,\n    data_output_prefix=\"dataOutputPrefix\",\n    encryption_key=key,\n    error_output_prefix=\"errorOutputPrefix\"\n)",
          "version": "2"
        },
        "csharp": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KMS;\n\nCompression compression;\nKey key;\nSize size;\n\nCommonDestinationS3Props commonDestinationS3Props = new CommonDestinationS3Props {\n    BufferingInterval = Duration.Minutes(30),\n    BufferingSize = size,\n    Compression = compression,\n    DataOutputPrefix = \"dataOutputPrefix\",\n    EncryptionKey = key,\n    ErrorOutputPrefix = \"errorOutputPrefix\"\n};",
          "version": "1"
        },
        "java": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.kms.*;\n\nCompression compression;\nKey key;\nSize size;\n\nCommonDestinationS3Props commonDestinationS3Props = CommonDestinationS3Props.builder()\n        .bufferingInterval(Duration.minutes(30))\n        .bufferingSize(size)\n        .compression(compression)\n        .dataOutputPrefix(\"dataOutputPrefix\")\n        .encryptionKey(key)\n        .errorOutputPrefix(\"errorOutputPrefix\")\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "import kinesisfirehose_destinations_alpha \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import awscdk \"github.com/aws/aws-cdk-go/awscdk\"import kms \"github.com/aws/aws-cdk-go/awscdk/aws_kms\"\n\nvar compression compression\nvar key key\nvar size size\ncommonDestinationS3Props := &commonDestinationS3Props{\n\tbufferingInterval: cdk.duration.minutes(jsii.Number(30)),\n\tbufferingSize: size,\n\tcompression: compression,\n\tdataOutputPrefix: jsii.String(\"dataOutputPrefix\"),\n\tencryptionKey: key,\n\terrorOutputPrefix: jsii.String(\"errorOutputPrefix\"),\n}",
          "version": "1"
        },
        "$": {
          "source": "// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_destinations_alpha from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as cdk from 'aws-cdk-lib';\nimport { aws_kms as kms } from 'aws-cdk-lib';\n\ndeclare const compression: kinesisfirehose_destinations_alpha.Compression;\ndeclare const key: kms.Key;\ndeclare const size: cdk.Size;\nconst commonDestinationS3Props: kinesisfirehose_destinations_alpha.CommonDestinationS3Props = {\n  bufferingInterval: cdk.Duration.minutes(30),\n  bufferingSize: size,\n  compression: compression,\n  dataOutputPrefix: 'dataOutputPrefix',\n  encryptionKey: key,\n  errorOutputPrefix: 'errorOutputPrefix',\n};",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-destinations-alpha.CommonDestinationS3Props"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.CommonDestinationS3Props",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.aws_kms.IKey"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n// The code below shows an example of how to instantiate this type.\n// The values are placeholders you should change.\nimport * as kinesisfirehose_destinations_alpha from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as cdk from 'aws-cdk-lib';\nimport { aws_kms as kms } from 'aws-cdk-lib';\n\ndeclare const compression: kinesisfirehose_destinations_alpha.Compression;\ndeclare const key: kms.Key;\ndeclare const size: cdk.Size;\n/// !hide\n// Hoisted imports ended before !hide marker above\nimport { Construct } from \"constructs\";\nclass MyConstruct extends Construct {\nconstructor(scope: Construct, id: string) {\nsuper(scope, id);\n// Code snippet begins after !show marker below\n/// !show\n\nconst commonDestinationS3Props: kinesisfirehose_destinations_alpha.CommonDestinationS3Props = {\n  bufferingInterval: cdk.Duration.minutes(30),\n  bufferingSize: size,\n  compression: compression,\n  dataOutputPrefix: 'dataOutputPrefix',\n  encryptionKey: key,\n  errorOutputPrefix: 'errorOutputPrefix',\n};\n/// !hide\n// Code snippet ended before !hide marker above\n} }",
      "syntaxKindCounter": {
        "8": 1,
        "10": 5,
        "75": 28,
        "130": 3,
        "153": 4,
        "169": 4,
        "193": 1,
        "194": 2,
        "196": 1,
        "225": 4,
        "242": 4,
        "243": 4,
        "254": 3,
        "255": 3,
        "256": 2,
        "257": 1,
        "258": 1,
        "281": 6,
        "290": 1
      },
      "fqnsFingerprint": "c54eb0539698b14831c5600659cc154eea5fb829051359e265831fa4f52e2d5d"
    },
    "6f6e130a6ff952ee26331a8508560ce44b492143b3637b797febb72c6fe8a7d1": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose_alpha as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "2"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "go": {
          "source": "import path \"github.com/aws-samples/dummy/path\"import firehose \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import kms \"github.com/aws/aws-cdk-go/awscdk\"import lambdanodejs \"github.com/aws/aws-cdk-go/awscdk\"import logs \"github.com/aws/aws-cdk-go/awscdk\"import s3 \"github.com/aws/aws-cdk-go/awscdk\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import destinations \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"\n\napp := cdk.NewApp()\n\nstack := cdk.NewStack(app, jsii.String(\"aws-cdk-firehose-delivery-stream-s3-all-properties\"))\n\nbucket := s3.NewBucket(stack, jsii.String(\"Bucket\"), &bucketProps{\n\tremovalPolicy: cdk.removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\n\nbackupBucket := s3.NewBucket(stack, jsii.String(\"BackupBucket\"), &bucketProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\nlogGroup := logs.NewLogGroup(stack, jsii.String(\"LogGroup\"), &logGroupProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\ndataProcessorFunction := lambdanodejs.NewNodejsFunction(stack, jsii.String(\"DataProcessorFunction\"), &nodejsFunctionProps{\n\tentry: path.join(__dirname, jsii.String(\"lambda-data-processor.js\")),\n\ttimeout: cdk.duration.minutes(jsii.Number(1)),\n})\n\nprocessor := firehose.NewLambdaFunctionProcessor(dataProcessorFunction, &dataProcessorProps{\n\tbufferInterval: cdk.*duration.seconds(jsii.Number(60)),\n\tbufferSize: cdk.size.mebibytes(jsii.Number(1)),\n\tretries: jsii.Number(1),\n})\n\nkey := kms.NewKey(stack, jsii.String(\"Key\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nbackupKey := kms.NewKey(stack, jsii.String(\"BackupKey\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nfirehose.NewDeliveryStream(stack, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\tlogging: jsii.Boolean(true),\n\t\t\tlogGroup: logGroup,\n\t\t\tprocessor: processor,\n\t\t\tcompression: destinations.compression_GZIP(),\n\t\t\tdataOutputPrefix: jsii.String(\"regularPrefix\"),\n\t\t\terrorOutputPrefix: jsii.String(\"errorPrefix\"),\n\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\tencryptionKey: key,\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.backupMode_ALL,\n\t\t\t\tbucket: backupBucket,\n\t\t\t\tcompression: destinations.*compression_ZIP(),\n\t\t\t\tdataOutputPrefix: jsii.String(\"backupPrefix\"),\n\t\t\t\terrorOutputPrefix: jsii.String(\"backupErrorPrefix\"),\n\t\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\t\tencryptionKey: backupKey,\n\t\t\t},\n\t\t}),\n\t},\n})\n\napp.synth()",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.App",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Duration#seconds",
        "aws-cdk-lib.RemovalPolicy",
        "aws-cdk-lib.RemovalPolicy#DESTROY",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.Stack",
        "aws-cdk-lib.Stage#synth",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_kms.Key",
        "aws-cdk-lib.aws_kms.KeyProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunctionProps",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_logs.LogGroup",
        "aws-cdk-lib.aws_logs.LogGroupProps",
        "aws-cdk-lib.aws_s3.Bucket",
        "aws-cdk-lib.aws_s3.BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as lambdanodejs from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cdk from 'aws-cdk-lib';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "47f33d4b0ee02f2364ebedbffe5a9fe2034492885858b06995f76713786ae1eb"
    },
    "e5cc48ccf309ac770f150433c63a24cfa9a354150701b52e142344267a0631fb": {
      "translations": {
        "python": {
          "source": "import path as path\nimport aws_cdk.aws_kinesisfirehose_alpha as firehose\nimport aws_cdk.aws_kms as kms\nimport aws_cdk.aws_lambda_nodejs as lambdanodejs\nimport aws_cdk.aws_logs as logs\nimport aws_cdk.aws_s3 as s3\nimport aws_cdk as cdk\nimport aws_cdk.aws_kinesisfirehose_destinations_alpha as destinations\n\napp = cdk.App()\n\nstack = cdk.Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\")\n\nbucket = s3.Bucket(stack, \"Bucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\n\nbackup_bucket = s3.Bucket(stack, \"BackupBucket\",\n    removal_policy=cdk.RemovalPolicy.DESTROY,\n    auto_delete_objects=True\n)\nlog_group = logs.LogGroup(stack, \"LogGroup\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\ndata_processor_function = lambdanodejs.NodejsFunction(stack, \"DataProcessorFunction\",\n    entry=path.join(__dirname, \"lambda-data-processor.js\"),\n    timeout=cdk.Duration.minutes(1)\n)\n\nprocessor = firehose.LambdaFunctionProcessor(data_processor_function,\n    buffer_interval=cdk.Duration.seconds(60),\n    buffer_size=cdk.Size.mebibytes(1),\n    retries=1\n)\n\nkey = kms.Key(stack, \"Key\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nbackup_key = kms.Key(stack, \"BackupKey\",\n    removal_policy=cdk.RemovalPolicy.DESTROY\n)\n\nfirehose.DeliveryStream(stack, \"Delivery Stream\",\n    destinations=[destinations.S3Bucket(bucket,\n        logging=True,\n        log_group=log_group,\n        processor=processor,\n        compression=destinations.Compression.GZIP,\n        data_output_prefix=\"regularPrefix\",\n        error_output_prefix=\"errorPrefix\",\n        buffering_interval=cdk.Duration.seconds(60),\n        buffering_size=cdk.Size.mebibytes(1),\n        encryption_key=key,\n        s3_backup=destinations.DestinationS3BackupProps(\n            mode=destinations.BackupMode.ALL,\n            bucket=backup_bucket,\n            compression=destinations.Compression.ZIP,\n            data_output_prefix=\"backupPrefix\",\n            error_output_prefix=\"backupErrorPrefix\",\n            buffering_interval=cdk.Duration.seconds(60),\n            buffering_size=cdk.Size.mebibytes(1),\n            encryption_key=backup_key\n        )\n    )]\n)\n\napp.synth()",
          "version": "2"
        },
        "csharp": {
          "source": "using Path;\nusing Amazon.CDK.AWS.KinesisFirehose.Alpha;\nusing Amazon.CDK.AWS.KMS;\nusing Amazon.CDK.AWS.Lambda.Nodejs;\nusing Amazon.CDK.AWS.Logs;\nusing Amazon.CDK.AWS.S3;\nusing Amazon.CDK;\nusing Amazon.CDK.AWS.KinesisFirehose.Destinations.Alpha;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = new Bucket(stack, \"Bucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\n\nBucket backupBucket = new Bucket(stack, \"BackupBucket\", new BucketProps {\n    RemovalPolicy = RemovalPolicy.DESTROY,\n    AutoDeleteObjects = true\n});\nLogGroup logGroup = new LogGroup(stack, \"LogGroup\", new LogGroupProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nNodejsFunction dataProcessorFunction = new NodejsFunction(stack, \"DataProcessorFunction\", new NodejsFunctionProps {\n    Entry = Join(__dirname, \"lambda-data-processor.js\"),\n    Timeout = Duration.Minutes(1)\n});\n\nLambdaFunctionProcessor processor = new LambdaFunctionProcessor(dataProcessorFunction, new DataProcessorProps {\n    BufferInterval = Duration.Seconds(60),\n    BufferSize = Size.Mebibytes(1),\n    Retries = 1\n});\n\nKey key = new Key(stack, \"Key\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nKey backupKey = new Key(stack, \"BackupKey\", new KeyProps {\n    RemovalPolicy = RemovalPolicy.DESTROY\n});\n\nnew DeliveryStream(stack, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { new S3Bucket(bucket, new S3BucketProps {\n        Logging = true,\n        LogGroup = logGroup,\n        Processor = processor,\n        Compression = Compression.GZIP,\n        DataOutputPrefix = \"regularPrefix\",\n        ErrorOutputPrefix = \"errorPrefix\",\n        BufferingInterval = Duration.Seconds(60),\n        BufferingSize = Size.Mebibytes(1),\n        EncryptionKey = key,\n        S3Backup = new DestinationS3BackupProps {\n            Mode = BackupMode.ALL,\n            Bucket = backupBucket,\n            Compression = Compression.ZIP,\n            DataOutputPrefix = \"backupPrefix\",\n            ErrorOutputPrefix = \"backupErrorPrefix\",\n            BufferingInterval = Duration.Seconds(60),\n            BufferingSize = Size.Mebibytes(1),\n            EncryptionKey = backupKey\n        }\n    }) }\n});\n\napp.Synth();",
          "version": "1"
        },
        "java": {
          "source": "import path.*;\nimport software.amazon.awscdk.services.kinesisfirehose.alpha.*;\nimport software.amazon.awscdk.services.kms.*;\nimport software.amazon.awscdk.services.lambda.nodejs.*;\nimport software.amazon.awscdk.services.logs.*;\nimport software.amazon.awscdk.services.s3.*;\nimport software.amazon.awscdk.*;\nimport software.amazon.awscdk.services.kinesisfirehose.destinations.alpha.*;\n\nApp app = new App();\n\nStack stack = new Stack(app, \"aws-cdk-firehose-delivery-stream-s3-all-properties\");\n\nBucket bucket = Bucket.Builder.create(stack, \"Bucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\n\nBucket backupBucket = Bucket.Builder.create(stack, \"BackupBucket\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .autoDeleteObjects(true)\n        .build();\nLogGroup logGroup = LogGroup.Builder.create(stack, \"LogGroup\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nNodejsFunction dataProcessorFunction = NodejsFunction.Builder.create(stack, \"DataProcessorFunction\")\n        .entry(join(__dirname, \"lambda-data-processor.js\"))\n        .timeout(Duration.minutes(1))\n        .build();\n\nLambdaFunctionProcessor processor = LambdaFunctionProcessor.Builder.create(dataProcessorFunction)\n        .bufferInterval(Duration.seconds(60))\n        .bufferSize(Size.mebibytes(1))\n        .retries(1)\n        .build();\n\nKey key = Key.Builder.create(stack, \"Key\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nKey backupKey = Key.Builder.create(stack, \"BackupKey\")\n        .removalPolicy(RemovalPolicy.DESTROY)\n        .build();\n\nDeliveryStream.Builder.create(stack, \"Delivery Stream\")\n        .destinations(List.of(S3Bucket.Builder.create(bucket)\n                .logging(true)\n                .logGroup(logGroup)\n                .processor(processor)\n                .compression(Compression.GZIP)\n                .dataOutputPrefix(\"regularPrefix\")\n                .errorOutputPrefix(\"errorPrefix\")\n                .bufferingInterval(Duration.seconds(60))\n                .bufferingSize(Size.mebibytes(1))\n                .encryptionKey(key)\n                .s3Backup(DestinationS3BackupProps.builder()\n                        .mode(BackupMode.ALL)\n                        .bucket(backupBucket)\n                        .compression(Compression.ZIP)\n                        .dataOutputPrefix(\"backupPrefix\")\n                        .errorOutputPrefix(\"backupErrorPrefix\")\n                        .bufferingInterval(Duration.seconds(60))\n                        .bufferingSize(Size.mebibytes(1))\n                        .encryptionKey(backupKey)\n                        .build())\n                .build()))\n        .build();\n\napp.synth();",
          "version": "1"
        },
        "go": {
          "source": "import path \"github.com/aws-samples/dummy/path\"import firehose \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosealpha\"import kms \"github.com/aws/aws-cdk-go/awscdk\"import lambdanodejs \"github.com/aws/aws-cdk-go/awscdk\"import logs \"github.com/aws/aws-cdk-go/awscdk\"import s3 \"github.com/aws/aws-cdk-go/awscdk\"import cdk \"github.com/aws/aws-cdk-go/awscdk\"import destinations \"github.com/aws/aws-cdk-go/awscdkkinesisfirehosedestinationsalpha\"\n\napp := cdk.NewApp()\n\nstack := cdk.NewStack(app, jsii.String(\"aws-cdk-firehose-delivery-stream-s3-all-properties\"))\n\nbucket := s3.NewBucket(stack, jsii.String(\"Bucket\"), &bucketProps{\n\tremovalPolicy: cdk.removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\n\nbackupBucket := s3.NewBucket(stack, jsii.String(\"BackupBucket\"), &bucketProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n\tautoDeleteObjects: jsii.Boolean(true),\n})\nlogGroup := logs.NewLogGroup(stack, jsii.String(\"LogGroup\"), &logGroupProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\ndataProcessorFunction := lambdanodejs.NewNodejsFunction(stack, jsii.String(\"DataProcessorFunction\"), &nodejsFunctionProps{\n\tentry: path.join(__dirname, jsii.String(\"lambda-data-processor.js\")),\n\ttimeout: cdk.duration.minutes(jsii.Number(1)),\n})\n\nprocessor := firehose.NewLambdaFunctionProcessor(dataProcessorFunction, &dataProcessorProps{\n\tbufferInterval: cdk.*duration.seconds(jsii.Number(60)),\n\tbufferSize: cdk.size.mebibytes(jsii.Number(1)),\n\tretries: jsii.Number(1),\n})\n\nkey := kms.NewKey(stack, jsii.String(\"Key\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nbackupKey := kms.NewKey(stack, jsii.String(\"BackupKey\"), &keyProps{\n\tremovalPolicy: cdk.*removalPolicy_DESTROY,\n})\n\nfirehose.NewDeliveryStream(stack, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\tdestinations.NewS3Bucket(bucket, &s3BucketProps{\n\t\t\tlogging: jsii.Boolean(true),\n\t\t\tlogGroup: logGroup,\n\t\t\tprocessor: processor,\n\t\t\tcompression: destinations.compression_GZIP(),\n\t\t\tdataOutputPrefix: jsii.String(\"regularPrefix\"),\n\t\t\terrorOutputPrefix: jsii.String(\"errorPrefix\"),\n\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\tencryptionKey: key,\n\t\t\ts3Backup: &destinationS3BackupProps{\n\t\t\t\tmode: destinations.backupMode_ALL,\n\t\t\t\tbucket: backupBucket,\n\t\t\t\tcompression: destinations.*compression_ZIP(),\n\t\t\t\tdataOutputPrefix: jsii.String(\"backupPrefix\"),\n\t\t\t\terrorOutputPrefix: jsii.String(\"backupErrorPrefix\"),\n\t\t\t\tbufferingInterval: cdk.*duration.seconds(jsii.Number(60)),\n\t\t\t\tbufferingSize: cdk.*size.mebibytes(jsii.Number(1)),\n\t\t\t\tencryptionKey: backupKey,\n\t\t\t},\n\t\t}),\n\t},\n})\n\napp.synth()",
          "version": "1"
        },
        "$": {
          "source": "#!/usr/bin/env node",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.BackupMode#ALL",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#GZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.Compression#ZIP",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.DestinationS3BackupProps",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.App",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Duration#seconds",
        "aws-cdk-lib.RemovalPolicy",
        "aws-cdk-lib.RemovalPolicy#DESTROY",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.Stack",
        "aws-cdk-lib.Stage#synth",
        "aws-cdk-lib.aws_kms.IKey",
        "aws-cdk-lib.aws_kms.Key",
        "aws-cdk-lib.aws_kms.KeyProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunction",
        "aws-cdk-lib.aws_lambda_nodejs.NodejsFunctionProps",
        "aws-cdk-lib.aws_logs.ILogGroup",
        "aws-cdk-lib.aws_logs.LogGroup",
        "aws-cdk-lib.aws_logs.LogGroupProps",
        "aws-cdk-lib.aws_s3.Bucket",
        "aws-cdk-lib.aws_s3.BucketProps",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "#!/usr/bin/env node\n/// !cdk-integ pragma:ignore-assets\nimport * as path from 'path';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as lambdanodejs from 'aws-cdk-lib/aws-lambda-nodejs';\nimport * as logs from 'aws-cdk-lib/aws-logs';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as cdk from 'aws-cdk-lib';\nimport * as destinations from '../lib';\n\nconst app = new cdk.App();\n\nconst stack = new cdk.Stack(app, 'aws-cdk-firehose-delivery-stream-s3-all-properties');\n\nconst bucket = new s3.Bucket(stack, 'Bucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\n\nconst backupBucket = new s3.Bucket(stack, 'BackupBucket', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n  autoDeleteObjects: true,\n});\nconst logGroup = new logs.LogGroup(stack, 'LogGroup', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst dataProcessorFunction = new lambdanodejs.NodejsFunction(stack, 'DataProcessorFunction', {\n  entry: path.join(__dirname, 'lambda-data-processor.js'),\n  timeout: cdk.Duration.minutes(1),\n});\n\nconst processor = new firehose.LambdaFunctionProcessor(dataProcessorFunction, {\n  bufferInterval: cdk.Duration.seconds(60),\n  bufferSize: cdk.Size.mebibytes(1),\n  retries: 1,\n});\n\nconst key = new kms.Key(stack, 'Key', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nconst backupKey = new kms.Key(stack, 'BackupKey', {\n  removalPolicy: cdk.RemovalPolicy.DESTROY,\n});\n\nnew firehose.DeliveryStream(stack, 'Delivery Stream', {\n  destinations: [new destinations.S3Bucket(bucket, {\n    logging: true,\n    logGroup: logGroup,\n    processor: processor,\n    compression: destinations.Compression.GZIP,\n    dataOutputPrefix: 'regularPrefix',\n    errorOutputPrefix: 'errorPrefix',\n    bufferingInterval: cdk.Duration.seconds(60),\n    bufferingSize: cdk.Size.mebibytes(1),\n    encryptionKey: key,\n    s3Backup: {\n      mode: destinations.BackupMode.ALL,\n      bucket: backupBucket,\n      compression: destinations.Compression.ZIP,\n      dataOutputPrefix: 'backupPrefix',\n      errorOutputPrefix: 'backupErrorPrefix',\n      bufferingInterval: cdk.Duration.seconds(60),\n      bufferingSize: cdk.Size.mebibytes(1),\n      encryptionKey: backupKey,\n    },\n  })],\n});\n\napp.synth();\n",
      "syntaxKindCounter": {
        "8": 8,
        "10": 21,
        "75": 135,
        "106": 3,
        "192": 1,
        "193": 10,
        "194": 43,
        "196": 9,
        "197": 11,
        "225": 9,
        "226": 2,
        "242": 9,
        "243": 9,
        "254": 8,
        "255": 8,
        "256": 8,
        "281": 31,
        "290": 1
      },
      "fqnsFingerprint": "47f33d4b0ee02f2364ebedbffe5a9fe2034492885858b06995f76713786ae1eb"
    },
    "e0811b3f0df27e4abcb1d4d464684d6bbe7a73ec1c48e1ae2719faf983e25de1": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n# Provide a Lambda function that will transform records before delivery, with custom\n# buffering and retry configuration\nlambda_function = lambda_.Function(self, \"Processor\",\n    runtime=lambda_.Runtime.NODEJS_12_X,\n    handler=\"index.handler\",\n    code=lambda_.Code.from_asset(path.join(__dirname, \"process-records\"))\n)\nlambda_processor = firehose.LambdaFunctionProcessor(lambda_function,\n    buffer_interval=Duration.minutes(5),\n    buffer_size=Size.mebibytes(5),\n    retries=5\n)\ns3_destination = destinations.S3Bucket(bucket,\n    processor=lambda_processor\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = new Function(this, \"Processor\", new FunctionProps {\n    Runtime = Runtime.NODEJS_12_X,\n    Handler = \"index.handler\",\n    Code = Code.FromAsset(Join(__dirname, \"process-records\"))\n});\nLambdaFunctionProcessor lambdaProcessor = new LambdaFunctionProcessor(lambdaFunction, new DataProcessorProps {\n    BufferInterval = Duration.Minutes(5),\n    BufferSize = Size.Mebibytes(5),\n    Retries = 5\n});\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Processor = lambdaProcessor\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = Function.Builder.create(this, \"Processor\")\n        .runtime(Runtime.NODEJS_12_X)\n        .handler(\"index.handler\")\n        .code(Code.fromAsset(join(__dirname, \"process-records\")))\n        .build();\nLambdaFunctionProcessor lambdaProcessor = LambdaFunctionProcessor.Builder.create(lambdaFunction)\n        .bufferInterval(Duration.minutes(5))\n        .bufferSize(Size.mebibytes(5))\n        .retries(5)\n        .build();\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .processor(lambdaProcessor)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nlambdaFunction := lambda.NewFunction(this, jsii.String(\"Processor\"), &functionProps{\n\truntime: lambda.runtime_NODEJS_12_X(),\n\thandler: jsii.String(\"index.handler\"),\n\tcode: lambda.code.fromAsset(path.join(__dirname, jsii.String(\"process-records\"))),\n})\nlambdaProcessor := firehose.NewLambdaFunctionProcessor(lambdaFunction, &dataProcessorProps{\n\tbufferInterval: duration.minutes(jsii.Number(5)),\n\tbufferSize: size.mebibytes(jsii.Number(5)),\n\tretries: jsii.Number(5),\n})\ns3Destination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tprocessor: lambdaProcessor,\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\ts3Destination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.aws_lambda.Code",
        "aws-cdk-lib.aws_lambda.Code#fromAsset",
        "aws-cdk-lib.aws_lambda.Function",
        "aws-cdk-lib.aws_lambda.FunctionProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda.Runtime",
        "aws-cdk-lib.aws_lambda.Runtime#NODEJS_12_X",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 3,
        "10": 4,
        "75": 39,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 11,
        "196": 4,
        "197": 4,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "19b84849c80cea41c51f2778c3be6760cd40dc358f5808896db488d18daa930a"
    },
    "cf41a3c446119250f3ab06ab59042092489c6abfa163a531d8108ce2f6a97196": {
      "translations": {
        "python": {
          "source": "# bucket: s3.Bucket\n# Provide a Lambda function that will transform records before delivery, with custom\n# buffering and retry configuration\nlambda_function = lambda_.Function(self, \"Processor\",\n    runtime=lambda_.Runtime.NODEJS_12_X,\n    handler=\"index.handler\",\n    code=lambda_.Code.from_asset(path.join(__dirname, \"process-records\"))\n)\nlambda_processor = firehose.LambdaFunctionProcessor(lambda_function,\n    buffer_interval=Duration.minutes(5),\n    buffer_size=Size.mebibytes(5),\n    retries=5\n)\ns3_destination = destinations.S3Bucket(bucket,\n    processor=lambda_processor\n)\nfirehose.DeliveryStream(self, \"Delivery Stream\",\n    destinations=[s3_destination]\n)",
          "version": "2"
        },
        "csharp": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = new Function(this, \"Processor\", new FunctionProps {\n    Runtime = Runtime.NODEJS_12_X,\n    Handler = \"index.handler\",\n    Code = Code.FromAsset(Join(__dirname, \"process-records\"))\n});\nLambdaFunctionProcessor lambdaProcessor = new LambdaFunctionProcessor(lambdaFunction, new DataProcessorProps {\n    BufferInterval = Duration.Minutes(5),\n    BufferSize = Size.Mebibytes(5),\n    Retries = 5\n});\nS3Bucket s3Destination = new S3Bucket(bucket, new S3BucketProps {\n    Processor = lambdaProcessor\n});\nnew DeliveryStream(this, \"Delivery Stream\", new DeliveryStreamProps {\n    Destinations = new [] { s3Destination }\n});",
          "version": "1"
        },
        "java": {
          "source": "Bucket bucket;\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nFunction lambdaFunction = Function.Builder.create(this, \"Processor\")\n        .runtime(Runtime.NODEJS_12_X)\n        .handler(\"index.handler\")\n        .code(Code.fromAsset(join(__dirname, \"process-records\")))\n        .build();\nLambdaFunctionProcessor lambdaProcessor = LambdaFunctionProcessor.Builder.create(lambdaFunction)\n        .bufferInterval(Duration.minutes(5))\n        .bufferSize(Size.mebibytes(5))\n        .retries(5)\n        .build();\nS3Bucket s3Destination = S3Bucket.Builder.create(bucket)\n        .processor(lambdaProcessor)\n        .build();\nDeliveryStream.Builder.create(this, \"Delivery Stream\")\n        .destinations(List.of(s3Destination))\n        .build();",
          "version": "1"
        },
        "go": {
          "source": "var bucket bucket// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nlambdaFunction := lambda.NewFunction(this, jsii.String(\"Processor\"), &functionProps{\n\truntime: lambda.runtime_NODEJS_12_X(),\n\thandler: jsii.String(\"index.handler\"),\n\tcode: lambda.code.fromAsset(path.join(__dirname, jsii.String(\"process-records\"))),\n})\nlambdaProcessor := firehose.NewLambdaFunctionProcessor(lambdaFunction, &dataProcessorProps{\n\tbufferInterval: duration.minutes(jsii.Number(5)),\n\tbufferSize: size.mebibytes(jsii.Number(5)),\n\tretries: jsii.Number(5),\n})\ns3Destination := destinations.NewS3Bucket(bucket, &s3BucketProps{\n\tprocessor: lambdaProcessor,\n})\nfirehose.NewDeliveryStream(this, jsii.String(\"Delivery Stream\"), &deliveryStreamProps{\n\tdestinations: []iDestination{\n\t\ts3Destination,\n\t},\n})",
          "version": "1"
        },
        "$": {
          "source": "// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\ndeclare const bucket: s3.Bucket;\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});",
          "version": "0"
        }
      },
      "location": {
        "api": {
          "api": "type",
          "fqn": "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps"
        },
        "field": {
          "field": "example"
        }
      },
      "didCompile": true,
      "fqnsReferenced": [
        "@aws-cdk/aws-kinesisfirehose-alpha.DataProcessorProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStream",
        "@aws-cdk/aws-kinesisfirehose-alpha.DeliveryStreamProps",
        "@aws-cdk/aws-kinesisfirehose-alpha.IDataProcessor",
        "@aws-cdk/aws-kinesisfirehose-alpha.LambdaFunctionProcessor",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3Bucket",
        "@aws-cdk/aws-kinesisfirehose-destinations-alpha.S3BucketProps",
        "aws-cdk-lib.Duration",
        "aws-cdk-lib.Duration#minutes",
        "aws-cdk-lib.Size",
        "aws-cdk-lib.Size#mebibytes",
        "aws-cdk-lib.aws_lambda.Code",
        "aws-cdk-lib.aws_lambda.Code#fromAsset",
        "aws-cdk-lib.aws_lambda.Function",
        "aws-cdk-lib.aws_lambda.FunctionProps",
        "aws-cdk-lib.aws_lambda.IFunction",
        "aws-cdk-lib.aws_lambda.Runtime",
        "aws-cdk-lib.aws_lambda.Runtime#NODEJS_12_X",
        "aws-cdk-lib.aws_s3.IBucket"
      ],
      "fullSource": "// Hoisted imports begin after !show marker below\n/// !show\n\ndeclare const bucket: s3.Bucket;\n/// !hide\n// Hoisted imports ended before !hide marker above\n// Fixture with packages imported, but nothing else\nimport { Construct } from 'constructs';\nimport { Duration, Size, Stack } from 'aws-cdk-lib';\nimport * as firehose from '@aws-cdk/aws-kinesisfirehose-alpha';\nimport * as kinesis from 'aws-cdk-lib/aws-kinesis';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\nimport * as destinations from '@aws-cdk/aws-kinesisfirehose-destinations-alpha';\nimport * as kms from 'aws-cdk-lib/aws-kms';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as path from 'path';\n\nclass Fixture extends Stack {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Code snippet begins after !show marker below\n/// !show\n// Provide a Lambda function that will transform records before delivery, with custom\n// buffering and retry configuration\nconst lambdaFunction = new lambda.Function(this, 'Processor', {\n  runtime: lambda.Runtime.NODEJS_12_X,\n  handler: 'index.handler',\n  code: lambda.Code.fromAsset(path.join(__dirname, 'process-records')),\n});\nconst lambdaProcessor = new firehose.LambdaFunctionProcessor(lambdaFunction, {\n  bufferInterval: Duration.minutes(5),\n  bufferSize: Size.mebibytes(5),\n  retries: 5,\n});\nconst s3Destination = new destinations.S3Bucket(bucket, {\n  processor: lambdaProcessor,\n});\nnew firehose.DeliveryStream(this, 'Delivery Stream', {\n  destinations: [s3Destination],\n});\n/// !hide\n// Code snippet ended before !hide marker above\n  }\n}\n",
      "syntaxKindCounter": {
        "8": 3,
        "10": 4,
        "75": 39,
        "104": 2,
        "130": 1,
        "153": 1,
        "169": 1,
        "192": 1,
        "193": 4,
        "194": 11,
        "196": 4,
        "197": 4,
        "225": 4,
        "226": 1,
        "242": 4,
        "243": 4,
        "281": 8,
        "290": 1
      },
      "fqnsFingerprint": "19b84849c80cea41c51f2778c3be6760cd40dc358f5808896db488d18daa930a"
    }
  }
}
